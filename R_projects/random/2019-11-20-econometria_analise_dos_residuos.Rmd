---
title: ""
date: 2019-11-24
output:
  prettydoc::html_pretty:
    theme: architect
---

O modelo de regressão linear é bastante utilizado na predição de variáveis contínuas, onde há uma ou mais variáveis independentes e uma variável dependente (em que se busca comprovar uma hipótese sobre seu comportamento). Este é um modelo bastante simples de ser aplicado e um dos primeiros a ser ensinado nas aulas de econometria. Porém, apesar de sua simplicidade, para que o modelo gere resultados confiáveis, algumas premissas precisam ser satisfeitas, sendo elas:

i) Não existência de multicolinearidade entre as variáveis dependentes.

ii) Não existência de autocorrelação na variável dependente.

iii) Não existência de padrão no comportamento dos resíduos, ou seja, não ocorrência de heterocedasticidade.

iv) Distribuição normal dos resíduos.

Satisfazendo estas premissas, o modelo pode ser executado e as conclusões geradas serão confiáveis para permitir a tomada de decisão. 
Neste post, irei analisar o comportamento dos resíduos com um exemplo prático para validar as premissas (iii) e (iv). Para isso, vou usar uma base de dados que apresenta o preço da cana de açucar como variável independente e a área plantada (em hectares) de cana de açucar, que será a variável dependente (a.k.a explicativa).

A ideia deste exemplo é analisar, através de um modelo de regressão linear simples, a elasticidade da oferta da cana de açucar em função do preço de venda. A hipótese é que existe elasticidade na oferta, onde a área plantada aumenta conforme o preço aumenta. Porém para validar esta elasticidade, é necessário comprovar, através da regressão, que as variáveis possuem correlação e a validade das premissas (iii) e (iv) ajudarão a apoiar esta conclusão.

Para este exemplo, serão utilizados os pacotes abaixo:

```{r,eval=T,include=T,echo=T,warning=F,message=F}
library(tidyverse)
library(lmtest)
library(corrplot)
library(readxl)
library(gridExtra)
library(ggthemes)

# Definindo tema padrão dos gráficos
theme_set(theme_economist())
```

```{r,eval=T,include=F,echo=T}
dados <- readxl::read_excel("C:/Users/francisco.piccolo/Desktop/R/franciscopiccolo.github.io/base_de_dados/Econometria_exercicios/autocorrelacao_cana_de_acucar.xlsx")

# Alterando o nome dos campos
dados %>% 
  transmute(
    periodo = Período,
    area = Área,
    valor = `Preço da Cana de Açúcar`*100,
    log_area = log(area),
    log_valor = log(valor),
    delta_area = round((area/lag(area,1))-1,digits = 2),
    delta_log_area = round(log_area-lag(log_area,1),digits = 2),
    delta_valor = round((valor/lag(valor,1))-1,digits=2),
    delta_log_valor = round(log_valor-lag(log_valor),digits = 2),
    log_area_precicion = delta_area - delta_log_area,
    log_valor_precision = delta_valor - delta_log_valor
  ) -> dados_2
```

A base de dados deste exemplo contêm 34 registros, com informação de área plantada e preço da cana de açucar, ambos com a transformação em logarítmo natural inclusas. 

Abaixo consta uma amostra dos dados:

```{r,eval=T,include=T,echo=F}
dados_2 %>%
  select(periodo,area,valor,log_area,log_valor) %>% 
  head(10) %>% 
  knitr::kable(align = "c",digits = 3,caption = "Tabela 1: Amostra dos dados")
```

O modelo de regressão linear proposto para este exemplo é definido pela equação abaixo.

$$ lnY_t = \beta_1+\beta_2 (lnX_t) + U_t $$

Onde:

$Y_t$ = área plantada no ano t (em hectares), em log natural 

$X_t$ = preço no ano t, em log natural

Utiliza-se o logarítmo natural para que as variações de um período para o outro (e.g. período 1 para o período 2) sejam intepretadas como variação percentual. Esta interpretação de variação percentual é possivel apenas para transformações em logarítmo natural e ela é necessária por conta do conceito de elasticidade, que indica que uma variação percentual de uma variável provoca uma determinada variação percentual em outra variável, como se fosse uma sensibilidade relativa.

Abaixo, consta um exemplo desta propriedade particular do log natural. Veja que as variações brutas podem ser interpretadas como variações percentuais após a transformação em log natural. Para mais informações veja [artigo 1](https://people.duke.edu/~rnau/411log.htm) [artigo 2](https://dev.to/rokaandy/logarithmic-transformation-in-linear-regression-models-why-when-3a7c).

```{r,eval=T,echo=F,include=T}
data.frame(
    "Valor" = c(100,105,112,120),
    "Crescimento" = c("-","5.00%","6.67%","7.14%"),
    "Log natural" = c(log(100),log(105),log(112),log(120)),
    "Delta" = c("-",
                  paste(round(log(105)-log(100),4)*100,"%",sep = ""),
                  paste(round(log(112)-log(105),4)*100,"%",sep = ""),
                  paste(round(log(120)-log(112),4)*100,"%",sep = ""))
) %>% knitr::kable(caption = "Tabela 2: Valores com log na base e",digits = 3,align = "c")
```

Veja como o crescimento percentual dos valores (5.00%, 6.67% e 7.14%) ficam bem próximos do respectivo delta, que é a diferença entre o log natural do número com relação ao log natural do número anterior (e.g. 4.654 - 4.605 = 0.0488). Desta forma, se a equação estiver em logarítmo natural em ambos os lados, pode-se interpretar que a variação percentual na variável explicativa irá gerar uma variação percentual de $\beta_1$ na variável dependente.

Ao tentar criar esta mesma tabela com outros logarítmos (e.g. base 2 ou base 10), não se alcança os mesmos resultados. Portanto, esta interpretação e transformação só faz sentido com logaritmo natural.

```{r,eval=T,echo=F,include=T}
data.frame(
    "Valor" = c(100,105,112,120),
    "Crescimento" = c("-","5.00%","6.67%","7.14%"),
    "Log natural" = c(log(100,2),log(105,2),log(112,2),log(120,2)),
    "Delta" = c("-",
                  paste(round(log(105,2)-log(100,2),4)*100,"%",sep = ""),
                  paste(round(log(112,2)-log(105,2),4)*100,"%",sep = ""),
                  paste(round(log(120,2)-log(112,2),4)*100,"%",sep = ""))
) %>% knitr::kable(caption = "Tabela 3: Valores com log na base 2",digits = 3,align = "c")
```

```{r,eval=T,echo=F,include=T}
data.frame(
    "Valor" = c(100,105,112,120),
    "Crescimento" = c("-","5.00%","6.67%","7.14%"),
    "Log natural" = c(log(100,10),log(105,10),log(112,10),log(120,10)),
    "Delta" = c("-",
                  paste(round(log(105,10)-log(100,10),4)*100,"%",sep = ""),
                  paste(round(log(112,10)-log(105,10),4)*100,"%",sep = ""),
                  paste(round(log(120,10)-log(112,10),4)*100,"%",sep = ""))
) %>% knitr::kable(caption = "Tabela 4: Valores com log na base 10",digits = 3,align = "c")
```

Após entender esta propriedade do log natural, pode-se validar esta característica na tabela que será usada para o modelo de regressão. O campo delta_ _area mostra a variação percentual da área de um período com relação ao período anterior e o mesmo cálculo no campo delta_valor. No campo delta_log_valor e delta_log_area é feita a diferença entre o período com o período anterior e os campos log_area_precision e log_valor_precision fazem a diferença entre delta_area com delta_log_area e delta_valor com delta_log_valor. Quanto mais baixo o valor de log_area_precision e log_valor_precision, mais forte é a característica do log natural explicada anteriormente. Veja abaixo para ficar mais claro:

```{r,eval=T,include=T,echo=F,warning=F}
dados_2 %>% 
  knitr::kable(caption = "Tabela 5: Dados do modelo com a validação da característica do log natural",digits = 3,align = "c")
```

Após entender um dos motivos da transformação em log, podemos continuar com a construção do modelo para validar as premissas dos resíduos. O modelo e os gráficos serão todos feitos com utilização das variáveis transformadas em log natural.

O gráfico abaixo mostra o comportamento das variáveis estudadas e a curva de regressão.

```{r,eval = T,include = T,echo = T,fig.align = 'center',fig.width = 7.5,fig.height = 4}
dados_2 %>% 
  ggplot(aes(x=log_area,y=log_valor))+
  geom_point()+
  geom_smooth(method = "lm",se = T)+
  labs(
    title = "Relação entre Área e Preço da Cana (em log)",
    subtitle= "Indício de elasticidade",
    x = "Área de plantação (ln)",
    y = "Preço de venda (ln)"
  )
```

Nota-se que as variáveis possuem correlação linear, ou seja, há elasticidade de oferta neste mercado. Abaixo consta o sumário do modelo de regressão:

```{r,eval = T, include = T, echo = T, warning=F}
model <- lm(log_area~log_valor,data = dados_2)

summary(model)
```

A equação de regressão gerada pelo modelo é definida como: $lnY_t = 1.64 + 0.97 (lnX_t) + U_t$

O coeficiente de correlação (R²) ficou em 70.6%, o que mostra uma correlação significativa entre as variáveis. Porém, não basta apenas este resultado para gerar conclusões a respeito das variáveis estudadas, é preciso analisar as premissas com relação aos resíduos.

```{r,eval=T,include=F,echo=T}
residual <- residuals(model)
```

```{r,eval=T,include=F,echo=T}
df <- cbind(dados_2, residual)
```

Abaixo é apresentado o gráfico de distribuição dos resíduos para validação da normalidade de seu comportamento. Tanto o histograma quanto o gráfico quantil-quantil (a.k.a qq-plot) são boas formas visuais de se validar a normalidade dos resíduos.

```{r,eval = T,include = T,echo = T,fig.align = 'center',fig.width = 7.5,fig.height = 4}
df %>% 
  ggplot(aes(x=residual))+
  geom_histogram(binwidth = .05,alpha=.4,fill="dark orange")+
  labs(
    title = "Histograma dos resíduos",
    subtitle = "Aparente normalidade dos dados",
    x = "",
    y = ""
  )
```

```{r,eval = T,include = T,echo = T,fig.align = 'center',fig.width = 7.5,fig.height = 4}
df %>% 
  ggplot(aes(sample=residual))+
  geom_qq()+
  labs(
    title = "QQ-Plot dos resíduos",
    subtitle = "Corrobora a suposta normalidade dos dados",
    x = "",
    y = ""
  )
```

A visualização gráfica é uma das formas para validar o comportamento dos resíduos porém não a única. Alguns testes formais podem ser usados para esta validação, como o Durbin-Watson, Breusch-Godfrey (a.k.a teste LM) e Ljung–Box Q test.

Aplicando ao exemplo proposto, o teste Durbin-Watson gerou os resultados abaixo:

```{r,eval=T,include=T,echo=F,warning=F,message=F}
lmtest::dwtest(model)
```

O valor DW foi de 1.2912 e ele é usado para gerar a conclusão do teste. Para se concluir o teste, é preciso antes trazer os intervalos (DL e DU) que comparados com o valor DW. Para encontrar os valores de DL e DU veja esta [tablea](http://www.portalaction.com.br/analise-de-regressao/33-diagnostico-de-independencia).

De acordo com a tabela, sabendo a quantidade de registros (n = 33), a significância (0.05) e o nível de liberdade (degrees of freedom (df) = 1), que é o número de variáveis independentes, pode-se achar os valores DL e DU. Para este exercício tem-se:

**DL** = 1.35

**DU** = 1.49

O valor DW (1.2912) ficou acima de 0 e abaixo de DL, o que permite concluir que não há dependência entre os resíduos. 

Além deste teste, que verifica autocorrelação positiva dos resíduos, é necessário incluir outros testes que analisam autocorrelação negativa também. O teste Breusch-Godfrey pode ser aplicado neste caso.

```{r,eval=T,include=T,echo=F,warning=F,message=F}
df_residual <- data.frame(
  residual_1 = residual[-34],
  residual_2 = residual[-1]
)

bgtest(residual_1~residual_2,order = 1,data = df_residual)
```

