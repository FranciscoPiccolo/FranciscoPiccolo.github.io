---
  title: ""
date: 2019-11-30
output:
  prettydoc::html_pretty:
  theme: architect
---
  
```{r}
library(DAAG)
library(tidyverse)
library(ggthemes)
library(gapminder)
library(wbstats)
library(missmap)
library(Amelia)
library(gridExtra)
library(WVPlots)
library(corrplot)
library(psych)
```


Substituindo NA por algum outro valor em um vetor

```{r}
a <- c(NA,2,4,5,1)

a <- na.omit(a)

mean(a,na.rm = T) #na.rm = removendo valores NA

a[is.na(a)] <- 100 #substituindo o valor NA por 100

```

1) Os dados abaixo representam o tamanho da área em hectares e o preço em milhares de 15 casas na Austrália em 1999.

```{r}
df_ex_1 <- data.frame(
  area = c(694,905,802,1366,716,963,821,714,1018,887,790,696,771,1006,1191),
  price = c(192,215,215,274,112,185,212,220,276,260,221,255,260,293,375)
)
```

a) Plote um gráfico que relacione preço e área

```{r}
df_ex_1 %>% 
  ggplot(aes(x=area,y=price))+
  geom_point()
```

b) Veja a distribuição do preço através de um histograma

```{r}
df_ex_1 %>% 
  ggplot(aes(x=price))+
  geom_histogram()
```

c) Transforme os dados em logarítmo e analíse a correlação novamente

```{r}
df_ex_1 %>% 
  mutate(
    log_area = log(area),
    log_price = log(price)
  ) %>% 
  ggplot(aes(x=log_area,y=log_price))+
  geom_point()
```

```{r}
DAAG::possum %>% head()


str(possum)

possum %>% ncol()

Amelia::missmap(possum)

Amelia::missmap(adj_training_data,main = "Missing values vs Observed")
```

```{r}
ais %>% Amelia::missmap()

ais %>% View()

ais %>% nrow()
```

```{r}
rainforest %>% Amelia::missmap()

rainforest %>% View()
```

```{r}
rep(c(2,3,5),c(4,3,1))
```

```{r}
rep(c(3,1,1,5,7),length.out = 50)
```

Objetos dentro de um modelo LM

```{r}
a <- rnorm(100,10,4)

b <- a*rnorm(100,1,.3)

df <- data.frame(
  a,b
)

df %>% 
  ggplot(aes(x=a,y=b))+
  geom_point()

# Criando o modelo LM
model <- lm(a~b)

# Verificando objetos dentro do modelo
names(model)

# Extraindo os coeficientes do modelo LM
coef(model)

# Acessando um objeto específico do modelo LM
model$assign

# Acessando os resíduos
model$residuals
```

Sperman Rank correlation 

Distribuições de probabilidade

Distribuições Discretas:

Binomial: Moeda justa; lançamento de dados; retirada de cartas; etc


Exemplo: Probabilidade de ter (0, 1 ou 2) meninas em uma família de 2 crianças com a probabilidade de ser menina em 50%.

```{r}
dbinom(0:2, size = 2, prob = .5)

# Plotando o resultado
df_dbinom <- data.frame(
  a = dbinom(0:8, size = 8, prob = .5),
  b = 0:8
)

df_dbinom %>% 
  ggplot(aes(x=b,y=a))+
  geom_line()
```

Probabilidade binomial cumulativa: Calculando a probabilidade de uma família de 4 crianças não ter mais do que 2 meninas. É a mesma coisa que usar dbinom para encontrar a probabilidade de uma família com 4 crianças e ver a probabilidade de ter 0, 1 ou 2 meninas e somar cada uma destas probabilidades.

```{r}
dbinom(0:4,size = 4, prob = .5) # (0.0625 + 0.25 + 0.3750) = 0.6875

pbinom(q=2,size = 4,prob = .5) # Soma já realizada após calcular dbinom acima
```

```{r}
dbinom(x=10,size = 50,prob = .2)

pbinom(q=20,size = 50,prob = .2)
```

Trabalhando com o mesmo tipo de problema, porém com um outro foco (quantidade de eventos), usa-se qbinom. Esta função vai da probabilidade cumulativa (pbinom) para o número de eventos.

```{r}
qbinom(p = .99, size = 50, prob = .2)
```

Poisson distribution

Usada para modelar eventos raros. 
```{r}
dpois(x = 0:4, lambda = 3)
```

```{r}
pretty(1:15)


pretty(c(-0.0001,0.01), 30)
```

Normal distribution

```{r}
## Plot the normal density, in the range -3 to 3
z <- pretty(c(-3,3), 30) # Find ˜30 equally spaced points
ht <- dnorm(z) # By default: mean=0, variance=1
plot(z, ht, type="l", xlab="Normal deviate", ylab="Density", yaxs="i")
# yaxs="i" locates the axes at the limits of the data
```

```{r}
pnorm(1,mean = 0,sd = 1)
```

```{r}
qnorm(0.9,mean = 0, sd = 1)
```

Geração de números exponenciais com média 1/3

```{r}
a <- rexp(n=1000, rate=3)

plot(a,type = "l")
```

Amostragem de populações:

```{r}
DAAG::qreference(m=50,seed = 21, nrep = 5, nrows = 1)
```

```{r}
set.seed (21) # Use to reproduce the data in the figure
par(mfrow=c(2,3))
x <- pretty(c(6.5,13.5), 40)
for(i in 1:5){
y <- rnorm(50, mean=10, sd=1)
hist(y, prob=TRUE, xlim=c(6.5,13.5), ylim=c(0,0.5), main="")
lines(x, dnorm(x,10,1))
}
par(mfrow=c(1,1))
rm(x, y)
```

### Exercícios Capítulo 3

2) Crie um for loop para gerar 25 vezes números aleatórios usando rnorm(100). 

```{r}
saida <- rep(NA,25)

for(i in 1:25){
  saida[i] <- data.frame(
    rnorm(100)
  )
}

dados_saida <- data.frame(
  a = matrix(unlist(saida),nrow = 25,byrow = F),stringsAsFactors = F)
```

3) Crie uma função para gerar o resultado do exercício 2.

```{r}
fun <- function(x,y){
  saida <- rep(NA,x)
  for(i in 1:x){
    saida[i] <- data.frame(
      rnorm(y)
    )
  }
  print(data.frame(
    a = matrix(unlist(saida),ncol = x,byrow = T),stringsAsFactors = F))
}

fun(2,10)
```

4) Gere números aleatórios inserindo os parâmetros média e desvio padrão em 100 e 10 respectivamente e retire uma amostra de tamanho 20 deste vetor. 

```{r}
pop <- rnorm(n = 1000, mean = 100, sd = 10)

mean(pop)

sd(pop)
```

5) Crie 9 gráficos onde cada um possui um número maior de amostras retiradas de uma população com distribuição normal.

```{r}
g_500 <- ggplot(data = data.frame(a = sample(rnorm(n = 1000,mean = 100,sd = 10),size = 500)))+
  geom_histogram(aes(x=a))

g_300 <- ggplot(data = data.frame(a = sample(rnorm(n = 1000,mean = 100,sd = 10),size = 300)))+
  geom_histogram(aes(x=a))

g_200 <- ggplot(data = data.frame(a = sample(rnorm(n = 1000,mean = 100,sd = 10),size = 200)))+
  geom_histogram(aes(x=a))

g_100 <- ggplot(data = data.frame(a = sample(rnorm(n = 1000,mean = 100,sd = 10),size = 100)))+
  geom_histogram(aes(x=a))

g_70 <- ggplot(data = data.frame(a = sample(rnorm(n = 1000,mean = 100,sd = 10),size = 70)))+
  geom_histogram(aes(x=a))

g_50 <- ggplot(data = data.frame(a = sample(rnorm(n = 1000,mean = 100,sd = 10),size = 50)))+
  geom_histogram(aes(x=a))

g_30 <- ggplot(data = data.frame(a = sample(rnorm(n = 1000,mean = 100,sd = 10),size = 30)))+
  geom_histogram(aes(x=a))

g_20 <- ggplot(data = data.frame(a = sample(rnorm(n = 1000,mean = 100,sd = 10),size = 20)))+
  geom_histogram(aes(x=a))

g_5 <- ggplot(data = data.frame(a = sample(rnorm(n = 1000,mean = 100,sd = 10),size = 5)))+
  geom_histogram(aes(x=a))

gridExtra::grid.arrange(g_500,g_300,g_200,g_100,g_70,g_50,g_30,g_20,g_5)
```

6) Use a função de distribuição exponencial (dexp,pexp,qexp,rexp) para calcular a probabilidade de que em 21 dias alguma pessoa sofrerá um acidente de trânsito em uma dado cruzamento, dado que o intervalo entre os acidentes podem ser modelados por uma distribuição exponencial com taxa de 0.05 acidentes por dia.

```{r}
pexp(q = 21,rate = 0.05) # usando a fórmula pronta do R
```

Agora um exemplo com distribuição de Poisson. Dado que 17 casos de cancer ocorrem por minuto, calcule a probabilidade de ocorrerem 20 casos no próximo minuto.

```{r}
r = 17 # calculando na "mão"
k = 20
exp(-r)*((r^k)/factorial(k))

dpois(x=20,lambda = 17)
```

Plote um gráfico com a distribuição de probabilidade do caso acima considerando um range de 1 a 30 casos.

```{r}
ggplot(data = data.frame(x=1:30,y = as.vector(dpois(x=1:30,lambda = 17))))+
  geom_col(aes(x=x,y=y))
```

8) Usando a função rexp (que gera números aleatórios com base na distribuição exponencial), gere 100 números aleatórios com uma taxa de 0.2. Gere um gráfico de densidade das observações. Encontre a média amostral e compare com a média populacional, que será 1/taxa (1/0.2 = 5).

```{r}
rexp(n = 100, rate = .2)

mean(rexp(n = 100, rate = .2))

plot(rexp(n = 100, rate = .2),type = "l")
```

10) Os dados abaixo representam o aparecimento de feridas em ratos que estavam sendo estudados em um laboratório. 

```{r}
rats <- c(87,53,72,90,78,85,83)
```

Calcule a média e a variância. A modelagem de Poisson é apropriada para os dados? Se for, verifique através dos comandos "x <- rpois(7,78.3); mena(x);var(x)" como a média e a variância se diferem.

```{r}
x <- rpois(n=7,lambda = 78.3)

fun <- function(k,n,l){
  saida <- rep(NA,k)
  for(i in 1:k){
    saida[i] <- data.frame(
      a = mean(rpois(n=n,lambda = l)),
      b = var(rpois(n=n,lambda = l))
    )
  }
  print(data.frame(
    a = matrix(unlist(saida[1]),nrow = k,byrow = T),
    b = matrix(unlist(saida[2]),nrow = k,byrow = T),stringAsFactors = F))
}

fun(6,7,78.3)

```

11) Markov Chains: 

Fórmula básica para criar uma matriz de transição.
```{r}
Markov <- function (N=100, initial.value=1, P)
{
X <- numeric(N)
X[1] <- initial.value + 1
n <- nrow(P)
for (i in 2:N){
X[i] <- sample(1:n, size=1, prob=P[X[i-1],])}
X-1
}
```

11.a) Simule 15 valores de um lançamento de moeda, começando com um valor de R$2,00.

```{r}
Markov(N = 15, initial.value = 2,P = .5)
```

### Exercícios Capítulo 4

1) Use a base de dados 'nsw74demo' do pacote DAAG e um intervalo de confiança de 95% para encontrar o intervalo de renda de cada um dos anos da base (1974,75 e 78).

```{r}
# Conhecendo a base de dados
DAAG::nsw74demo %>% View()

DAAG::nsw74demo %>% 
  nrow()

# distribuição da renda ao longo dos anos
DAAG::nsw74demo %>% 
  tidyr::gather("campo","valor",8:10) %>% 
  ggplot(aes(x=valor,fill = campo))+
  geom_histogram(position = "identity",alpha=.4)+
  scale_x_log10()
  
# distribuição da idade dos respondentes da pesquisa
DAAG::nsw74demo %>% 
  ggplot(aes(x=age))+
  geom_histogram()

# distribuição dos anos de educação dos respondentes da pesquisa
DAAG::nsw74demo %>% 
  ggplot(aes(x=educ))+
  geom_histogram()
```

```{r}
# intervalo para 1974
DAAG::nsw74demo %>% 
  select(
    trt,
    re74
  ) %>%
  group_by(trt) %>% 
  summarise(
    sd = sd(re74),
    mean = mean(re74)
  ) %>% 
  mutate(
    lower_limit = mean-(1.96*sd),
    upper_limit = mean+(1.96*sd)
  )
```

```{r}
# intervalo para 1975
DAAG::nsw74demo %>% 
  select(
    trt,
    re75
  ) %>%
  group_by(trt) %>% 
  summarise(
    sd = sd(re75),
    mean = mean(re75)
  ) %>% 
  mutate(
    lower_limit = mean-(1.96*sd),
    upper_limit = mean+(1.96*sd)
  )
```

```{r}
# intervalo para 1978
DAAG::nsw74demo %>% 
  select(
    trt,
    re78
  ) %>%
  group_by(trt) %>% 
  summarise(
    sd = sd(re78),
    mean = mean(re78)
  ) %>% 
  mutate(
    lower_limit = mean-(1.96*sd),
    upper_limit = mean+(1.96*sd)
  )
```

2) Plote gráficos que apresentem o valor crítico do teste t-student usando 5% de confiança e variando de 1 até 100 o DF (degree of freedom).

```{r}
# T-test usa qt, dt, pt, rt; Para valor crítico, usa-se qt.
t_value <- data.frame(
  df = seq(1,100,by = 1)
)

t_value %>% 
  mutate(
    t_value = qt(0.975,df = row_number())      # 0.975 pq é um teste dos dois lados da curva, ai tem-se 5/2 = 2.5 >> 100 = 97.5%
  ) %>% 
  ggplot(aes(x=df,y=t_value,group=1))+
  geom_line()+
  scale_x_log10()
```

3) Gere um dataset com 10 números aleatórios com base em uma distribuição normal (média 0 e desvio 2). Use t.test() para verificar a hipótese nula de que a média é 0.

```{r}
vector <- as.vector(rnorm(10,mean = 1.5,sd = 2))

t.test(vector,mu = 0)
```

5) O código abaixo irá desenhar uma matriz 2x2, 10 boxplots de 1.000 números aleatórios com uma distribuição normal, 10 boxplots de 1.000 números aleatórios de uma distribuição de student com DF = 7, 10 boxplot de 200 números aleatórios de uma distribuição normal e 10 boxplots de 200 números aleatórios de uma distribuição de student com DF = 7.

```{r}
oldpar <- par(mfrow=c(2,2))
tenfold1000 <- rep(1:10, rep(1000,10))
boxplot(split(rnorm(1000*10), tenfold1000), ylab="normal - 1000")
boxplot(split(rt(1000*10, 7), tenfold1000),
ylab=expression(t[7]*" - 1000"))
tenfold100 <- rep(1:10, rep(200, 10))
boxplot(split(rnorm(200*10), tenfold100), ylab="normal - 200")
boxplot(split(rt(200*10, 7), tenfold100),
ylab=expression(t[7]*" - 200"))
par(oldpar)
```

7) Crie uma função que faça o cálculo abaixo. Repita esta função em um loop 25 vezes. Obtenha a média e a variância de cada vetor gerado pelo loop. Depois calcule a variância das médias calculadas para cada iteração.

```{r}
y1 <- rnorm(51)
y <- y1[-1] + y1[-51]
```

```{r}
# Criando um vetor vazio com 25 entradas
saida <- rep(NA,25)

# Criando um loop com o cálculo acima
for(i in 1:25){
  y1 <- rnorm(51)
  saida[i] <- data.frame(
  a = y1[-1] + y1[-51]
  )
}

# Extraindo os valores do vetor e colocando em um data.frame
dados_saida <- data.frame(
  a = matrix(unlist(saida),nrow = 25,byrow = F),stringsAsFactors = F)


# Criando os campos com média e variância do resultado anterior (y1[-1] + y1[-51])
dados_saida %>%
  mutate(
    avg = mean(1:50),
    var = var(1:50)
  ) %>% 
  head()

# Obtendo a variância do campo avg
dados_saida %>%
  mutate(
    avg = mean(1:50),
    var = var(1:50)
  ) %>% 
  group_by() %>% 
  summarise(
    var_avg = var(avg) %>% 
      head()
  )
```

8) Usando o dataset 'nsw74psidl' do pacote DAAG, encontre as principais diferenças entre o grupo de controle e grupo de teste nas variáveis contínuas e discretas.

```{r}
DAAG::nsw74psid1 %>% 
  View()

# A primeira grande diferença é na quantidade de registros em cada grupo
DAAG::nsw74psid1 %>% 
  group_by(trt) %>% 
  summarise(
    count = n()
  ) %>% 
  head()
```

```{r}
# A distribuição de idades não difere tanto
DAAG::nsw74psid1 %>% 
  ggplot(aes(x=age))+
  geom_histogram(position = "identity",alpha=.4)+
  facet_grid(~trt)
```

```{r}
# O grupo de controle (trt == 0) possui grande concentração de anos de educação = 12
DAAG::nsw74psid1 %>% 
  ggplot(aes(x=educ))+
  geom_histogram(position = "identity",alpha=.4)+
  facet_grid(~trt)

DAAG::nsw74psid1 %>% 
  group_by(educ) %>%
  summarise(
    count = n()
  ) %>% 
  head(20)
```

### Exercícios Capítulo 5

1) Usando os dados de teste de elasticidade de elásticos, plote em um mesmo gráfico os dois grupos de teste. Verifique se os resultados aparentam ser consistentes.

```{r}
# Dados para o modelo
elastic_df_1 <- data.frame(
  stretch = c(46,54,48,50,44,42,52),
  distance = c(183,217,189,208,178,150,249)
)

elastic_df_2 <- data.frame(
  stretch = c(25,45,35,40,55,50,30,50,60),
  distance = c(71,196,127,187,249,217,114,228,291)
)

ggplot()+
  geom_point(data = elastic_df_1,aes(x=stretch,y=distance),color="blue")+
  geom_point(data = elastic_df_2,aes(x=stretch,y=distance),color="red")+
  geom_smooth(data = elastic_df_1,aes(x=stretch,y=distance),method = "lm",se = F)+
  geom_smooth(data = elastic_df_2,aes(x=stretch,y=distance),method = "lm",se = F,color="red")
```

2) Para os dados de elasticidade dos elásticos, verifique a regressão da elasticidade sobre a distância. Determine os valores estimados e o erro padrão e o R². Compare os dois resultados e indique qual a principal diferença entre os dois grupos.

```{r}
model_elastic_1 <- lm(formula = stretch~distance, data = elastic_df_1)

summary(model_elastic_1)

model_elastic_2 <- lm(formula = stretch~distance, data = elastic_df_2)

summary(model_elastic_2)

df_predicted_1 <- cbind(predict(model_elastic_1),elastic_df_1)

df_predicted_1 <- df_predicted_1 %>% mutate(predict = `predict(model_elastic_1)`)

df_predicted_1 %>% 
  ggplot(aes(x=stretch,y=predict))+
  geom_point()
```

3) Use o data set cars, que mostra a distância de frenagem e velocidade, para plotar um gráfico de dispersão entre distância e velocidade. Encontre uma linha de regressão linear e uma linha de regressão linear porém quadrática (x²). Verifique se a regressão quadrática gera resultados melhores.

```{r}
cars %>%
  ggplot(aes(x=speed,y=dist))+
  geom_point()+
  geom_smooth(method = "lm",formula = y~x+I(x^2),se = F,color="red",alpha=.7)+
  geom_smooth(method = "lm",formula = y~x,se = F,color="orange")

cars$dist_2 <- cars$dist^2

# Linear
summary(lm(formula = speed~dist,data = cars))

# Quadrática
summary(lm(formula = speed~dist+dist_2,data = cars))
```

4) Use o data set oddbooks (DAAG) para calcular área de volume dos livros.

a) Plote log(weight) vs log(volume) e encontre uma linha de regressão.

b) Plote log(weight) vs log(area) e encontre uma linha de regressão.

c) Indique qual das linhas de regressão geram um fit melhor.

d) Repita a) e b) porém usando log(density) ao invés de log(weight) como variável dependente.

5) No data set pressure (datasets), verifique a dependência da pressão sobre a temperatura.

6) Analise a função boxcox (MASS) e utilize-a no exercício 5. 

9) Usando o data set nsw74demo (DAAG), plote a renda de 1975 vs a renda de 1974. Verifique quais características do gráfico fazem a criação da reta de regressão ser difícil. Depois, plote log(income1975) vs log(income1974) e crie a reta de regressão. 

10) Crie uma função que gere dados que correspondam ao modelo de regressão: $y = 2 + 3x + e$

### Exercícios Capítulo 6

1) O data set cities (DAAG) lista a população (em milhares) das maiores cidades do Canada, de 1992 até 1996. Plote a população de 1996 vs a população de 1992 usando cores diferentes para distinguir as duas categorias de cidade (com rápido crescimento e sem rápido crescimento). Depois plote o mesmo gráfico porém usando logaritmo dos valores e analise a diferença. Indique qual gráfico é prefirível. Aplique um modelo de regressão linear, um com valores sem transformação e outro com transformação em log e interprete os resultados e as diferenças.

```{r}
# Plotando a população de 92 vs 96, sem transformação
cities %>% 
  mutate(have = as.character(ifelse((REGION %in% c("ON","WEST")),1,0))) %>% 
  ggplot(aes(x = POP1992, y = POP1996, color = have))+
  geom_point()
```

```{r}
# Plotando a população de 92 vs 96, com transformação log
cities %>% 
  mutate(have = as.character(ifelse((REGION %in% c("ON","WEST")),1,0))) %>% 
  ggplot(aes(x = log(POP1992), y = log(POP1996), color = have))+
  geom_point()
```

R: O gráfico com transformação log é preferível, pois normaliza os valor.

```{r}
# Regressão dos dados sem tranformação
cities.lm1 <- lm(POP1996 ~ have + POP1992, data = cities %>% 
  mutate(have = as.character(ifelse((REGION %in% c("ON","WEST")),1,0))))

# Regressão dos dados com tranformação log
cities.lm2 <- lm(log(POP1996) ~ have + log(POP1992), data = cities %>% 
  mutate(have = as.character(ifelse((REGION %in% c("ON","WEST")),1,0))))
```

```{r}
summary(cities.lm1)

summary(cities.lm2)
```

R: O modelo 2 é melhor, apesar do R² ser alto nos dois, o Std.Error é menor no segundo modelo e o F statistic é maior no segundo modelo.

2) Usando o data set cement (MASS), examine a dependência de Y (qtd de calor produzido) em X1, X2, X3 e X4. Plote uma matriz de gráficos de dispersão. Verifique se as variáveis explicativas precisam de transformação (talvez usando log(x/100-x))? Verifique se há outras alternatias que podem ser úteis para encontrar uma equação para prever o calor.

```{r}
# Plotando o gráfico nas variáveis sem transformação
psych::pairs.panels(MASS::cement,
                    method = "pearson",
                    hist.col = "#00AFBB",
                    density = T,
                    ellipses = T)
```

```{r}
# Dados transformados
MASS::cement %>%
  mutate(x1_adj = (log(x1/100)-x1),
         x2_adj = (log(x2/100)-x2),
         x3_adj = (log(x3/100)-x3),
         x4_adj = (log(x4/100)-x4)
         ) %>% 
  select(x1_adj,x2_adj,x3_adj,x4_adj,y) %>% 
  psych::pairs.panels(
                      method = "pearson",
                      hist.col = "#00AFBB",
                      density = T,
                      ellipses = T)
```

3) Usando o data set hills2000 do pacote DAAG, que contém informação da Corrida Escocesa. Construa um modelo de regressão para homens e mulheres separadamente. 

```{r}
DAAG::hills %>% 
  head()
```


