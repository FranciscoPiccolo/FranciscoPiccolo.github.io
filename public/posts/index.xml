<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on Glass Frog</title>
        <link>/posts/</link>
        <description>Recent content in Posts on Glass Frog</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Sat, 30 Nov 2019 00:00:00 +0000</lastBuildDate>
        <atom:link href="/posts/index.xml" rel="self" type="application/rss+xml" />
        
        <item>
            <title>Accessing World Bank database using R</title>
            <link>/posts/2019/11/accessing-world-bank-database-using-r/</link>
            <pubDate>Sat, 30 Nov 2019 00:00:00 +0000</pubDate>
            
            <guid>/posts/2019/11/accessing-world-bank-database-using-r/</guid>
            <description>The World Bank was created in 1944 at the Bretton Woords Conferences and its goal is to fight poverty and inequality, throughout investments and support for developing countries. The institution’s mission can be found on its webpage and the first target seeing at the is reduce to 3% the share of people living on extreme poverty until 2030. When the World Bank was created, one of its first responsibilities was to support Europe’s infrastructure reconstrution that had been devastated by the second world war 1.</description>
            <content type="html"><![CDATA[


<p>The World Bank was created in 1944 at the Bretton Woords Conferences and its goal is to fight poverty and inequality, throughout investments and support for developing countries. The institution’s mission can be found on its <a href="https://www.worldbank.org/en/who-we-are">webpage</a> and the first target seeing at the is reduce to 3% the share of people living on extreme poverty until 2030. When the World Bank was created, one of its first responsibilities was to support Europe’s infrastructure reconstrution that had been devastated by the second world war <a href="https://www.economist.com/the-economist-explains/2019/04/09/how-does-the-world-bank-work">1</a>.</p>
<p>In order to reach its purpose, the institution relies on a huge database to support the development of research for countries in need of advise and investments. This database was built and it keeps being by the institution and it can be found <a href="https://data.worldbank.org/indicator">here</a>. Anyone can access this database, including R users, that can count with an API to access this database easier. The World Bank API is presented on the R package “wbstats” and this package will be the focus of this post.</p>
<p>To explore this package in this post, I’ll analyse some indicators controlled by the World Bank. Just to note, this package was created by Jesse Piburn in 2018 january. The indicators that I’ll analyse will be GDP, Gini, Debt and Trade. As well as “wbstats” package, I’ll use other packages to execute the datamanipulation task.</p>
<pre class="r"><code>library(wbstats)
library(tidyverse)
library(ggthemes)
library(ggalt)
library(scales)

theme_graph &lt;- function(){
  theme(
    plot.title = element_text(size = 16),
    plot.subtitle = element_text(size = 12),
    plot.caption = element_text(face = &quot;italic&quot;, size = 9),
    axis.text = element_text(size = 9),
    axis.title = element_text(face = &quot;italic&quot;, size = 9),
    text = element_text(family = &quot;Times New Roman&quot;),
    strip.background = element_rect(fill = &quot;grey&quot;),
    strip.text = element_text(face = &quot;bold&quot;),
    legend.title = element_blank(),
    legend.position = &quot;bottom&quot;
  )
}
  
graph_color &lt;- &quot;#006666&quot;</code></pre>
<p>The “wb” function of the package seems to be the most important, it does the dowload of the data throughout the API e the output is a data.frame object. The main parameters of the function are: “indicator”, “country”, “startdate” and “enddate”. The indicador is a code that can be found on the World Bank URL page, for example, if you wanna take GDP per capita indicator in 2010 dolar, the URL is (<a href="https://data.worldbank.org/indicator/NY.GDP.MKTP.KD?view=chart" class="uri">https://data.worldbank.org/indicator/NY.GDP.MKTP.KD?view=chart</a>) and the code to insert on the “wb” function is <strong>“NY.GDP.MKTP.KD”</strong>. The country parameter can be one country in the iso2c format (e.g. “BR”, “AF” or “US”), a region (e.g. “1A” = Arabic countries“), all countries and regions using”all" or just countries using “countries_only”. Startdate and enddate parameters requires the data that you wanna the indicador, like from data &gt; to date, and these two parameters can be replaced by the parameter “mrv” that means “most recent value” and this parameter will require an integer to indicate how many data points will be dowloaded (e.g. mrv = 5 means the 5 most recent values of the indicator).</p>
<p>Lets see some indicators of the institution to analyse how the database is organized. To start, I’ll extract GDP per capita indicator at 2010 dolar values for the latim america region. In case you have some doubts about the country name, you can check at the indicator webpage.</p>
<pre class="r"><code># extracting the data and saving as a data.frame
df_gdp_pc &lt;- wbstats::wb(indicator = &quot;NY.GDP.PCAP.CD&quot;,
                         country = &quot;all&quot;,
                         startdate = 1990,
                         enddate = 2010)

# filtering the required countries
df_gdp_pc %&gt;% 
  select(country,value,date) %&gt;% 
  filter(country %in% c(&quot;Brazil&quot;,&quot;Chile&quot;,&quot;Ecuador&quot;,
                        &quot;Venezuela, RB&quot;,&quot;Colombia&quot;,
                        &quot;Peru&quot;,&quot;Argentina&quot;,&quot;Bolivia&quot;,
                        &quot;Uruguay&quot;,&quot;Paraguay&quot;)) %&gt;% 
  arrange(date) %&gt;% 
  head(10)</code></pre>
<pre><code>##          country     value date
## 1      Argentina 4333.4830 1990
## 2        Bolivia  709.0597 1990
## 3         Brazil 3100.2805 1990
## 4          Chile 2494.5257 1990
## 5       Colombia 1445.3284 1990
## 6        Ecuador 1489.5295 1990
## 7       Paraguay 1376.1647 1990
## 8           Peru 1196.5869 1990
## 9        Uruguay 2990.3642 1990
## 10 Venezuela, RB 2475.3805 1990</code></pre>
<p>Having the data organized as a data.frame, lets see the GDP per capita of the selected countries between 1990 and 2010.</p>
<pre class="r"><code>df_gdp_pc %&gt;% 
  select(country,value,date) %&gt;% 
  filter(country %in% c(&quot;Brazil&quot;,&quot;Chile&quot;,&quot;Ecuador&quot;,&quot;Venezuela, RB&quot;
                        ,&quot;Colombia&quot;,&quot;Peru&quot;,&quot;Argentina&quot;
                        ,&quot;Bolivia&quot;,&quot;Uruguay&quot;,&quot;Paraguay&quot;)) %&gt;% 
  filter(date %in% c(&quot;1990&quot;,&quot;2010&quot;)) %&gt;% 
  mutate(country = fct_reorder(country,value)) %&gt;% 
  ggplot(aes(x=country,y=value))+
  geom_col(fill=&quot;dark orange&quot;)+
  coord_flip()+
  theme_graph()+
  labs(title = &quot;GDP per Capita&quot;,
       subtitle = &quot;2010 US$ conversion&quot;,
       x = &quot;&quot;,
       y = &quot;&quot;)+
  facet_grid(~date)</code></pre>
<p><img src="/posts/2019-11-30-accessing-world-bank-database-using-R_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>As well as the GDP per capital, it’s interesting to visualize the growth of this indicator. On the following graphs we’ll verify which are the 30 countries that had the greatest variation of this indicator and also the 30 countries with the lowest variation, considering the same period of 1990 to 2010. For this analyse I’ve made a simple “case when” statement to classify the countries in groups of “low income”, “middle income” and “high income”.</p>
<pre class="r"><code>df_gdp_pc_2 &lt;- wbstats::wb(indicator = &quot;NY.GDP.PCAP.CD&quot;,
                           country = &quot;countries_only&quot;,
                           startdate = 1990,
                           enddate = 2010)

df_gdp_pc_2 %&gt;%
  select(date,
         country,
         value) %&gt;% 
  filter(date %in% c(&quot;1990&quot;,max(date))) %&gt;% 
  mutate(gdp_90 = ifelse(date == &quot;1990&quot;,value,0),
         gdp_10 = ifelse(date == &quot;2010&quot;,value,0)) %&gt;% 
  group_by(country) %&gt;% 
  summarise(gdp_90 = sum(gdp_90),
            gdp_10 = sum(gdp_10)) %&gt;% 
  filter(gdp_90 &gt; 0 &amp; gdp_10 &gt; 0) %&gt;% 
  mutate(delta = round(1-(gdp_90/gdp_10),digits = 4),
         income_range = ifelse(gdp_10 &lt;= 5000,&quot;low&quot;,
                        ifelse(gdp_10 &lt;= 15000,&quot;middle&quot;,
                        ifelse(gdp_10 &lt;= 45000,&quot;up_middle&quot;,
                        ifelse(gdp_10 &lt;= 60000,&quot;high&quot;,
                        ifelse(gdp_10 &lt;= 90000,&quot;up_high&quot;,
                        &quot;ultra_rich&quot;)))))) %&gt;% 
  filter(income_range == &quot;low&quot;) %&gt;% 
  arrange(desc(delta)) %&gt;% 
  head(20) %&gt;% 
  ggplot()+
  ggalt::geom_dumbbell(aes(y = fct_reorder(country, gdp_10),
                           x = gdp_90,
                           xend = gdp_10),
  colour = &quot;#3E39CD&quot;, size = 1,
  colour_x = &quot;#BD274A&quot;, colour_xend = &quot;#60AF1A&quot;)+
  scale_x_continuous(labels = scales::comma)+ # separando por vírgula (&#39;000)
  theme_graph()+
  labs(title = &quot;20 countries with the highest per capita GDP variation&quot;,
       subtitle = &quot;Group: Low income (GDP per capita &lt;= 5.000 US$ (2010))&quot;)</code></pre>
<p><img src="/posts/2019-11-30-accessing-world-bank-database-using-R_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>The preceding code can be replied, changing the filter “income_range == low”, to middle, up_middle, high and up_high income.</p>
<pre class="r"><code>df_gdp_pc_2 %&gt;%
  select(date,
         country,
         value) %&gt;% 
  filter(date %in% c(&quot;1990&quot;,max(date))) %&gt;% 
  mutate(gdp_90 = ifelse(date == &quot;1990&quot;,value,0),
         gdp_10 = ifelse(date == &quot;2010&quot;,value,0)) %&gt;% 
  group_by(country) %&gt;% 
  summarise(gdp_90 = sum(gdp_90),
            gdp_10 = sum(gdp_10)) %&gt;% 
  filter(gdp_90 &gt; 0 &amp; gdp_10 &gt; 0) %&gt;% 
  mutate(delta = round(1-(gdp_90/gdp_10),digits = 4),
         income_range = ifelse(gdp_10 &lt;= 5000,&quot;low&quot;,
                        ifelse(gdp_10 &lt;= 15000,&quot;middle&quot;,
                        ifelse(gdp_10 &lt;= 45000,&quot;up_middle&quot;,
                        ifelse(gdp_10 &lt;= 60000,&quot;high&quot;,
                        ifelse(gdp_10 &lt;= 90000,&quot;up_high&quot;,
                        &quot;ultra_rich&quot;)))))) %&gt;% 
  filter(income_range == &quot;middle&quot;) %&gt;% 
  arrange(desc(delta)) %&gt;% 
  head(20) %&gt;% 
  ggplot()+
  ggalt::geom_dumbbell(aes(y = fct_reorder(country,gdp_10),
                           x = gdp_90,
                           xend = gdp_10),
  colour = &quot;#3E39CD&quot;, size = 1,
  colour_x = &quot;#BD274A&quot;, colour_xend = &quot;#60AF1A&quot;)+
  scale_x_continuous(labels = comma)+ # separando por vírgula (&#39;000)
  theme_graph()+
  labs(title = &quot;20 countries with the highest per capita GDP variation&quot;,
       subtitle = &quot;Group: Middle income (GDP per capita &lt;= 15.000 US$ (2010))&quot;)</code></pre>
<p><img src="/posts/2019-11-30-accessing-world-bank-database-using-R_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<pre class="r"><code>df_gdp_pc_2 %&gt;%
  select(date,
         country,
         value) %&gt;% 
  filter(date %in% c(&quot;1990&quot;,max(date))) %&gt;% 
  mutate(gdp_90 = ifelse(date == &quot;1990&quot;,value,0),
         gdp_10 = ifelse(date == &quot;2010&quot;,value,0)) %&gt;% 
  group_by(country) %&gt;% 
  summarise(gdp_90 = sum(gdp_90),
            gdp_10 = sum(gdp_10)) %&gt;% 
  filter(gdp_90 &gt; 0 &amp; gdp_10 &gt; 0) %&gt;% 
  mutate(delta = round(1-(gdp_90/gdp_10),digits = 4),
         income_range = ifelse(gdp_10 &lt;= 5000,&quot;low&quot;,
                        ifelse(gdp_10 &lt;= 15000,&quot;middle&quot;,
                        ifelse(gdp_10 &lt;= 45000,&quot;up_middle&quot;,
                        ifelse(gdp_10 &lt;= 60000,&quot;high&quot;,
                        ifelse(gdp_10 &lt;= 90000,&quot;up_high&quot;,
                        &quot;ultra_rich&quot;)))))) %&gt;% 
  filter(income_range == &quot;up_middle&quot;) %&gt;% 
  arrange(desc(delta)) %&gt;% 
  head(20) %&gt;% 
  ggplot()+
  ggalt::geom_dumbbell(aes(y = fct_reorder(country,gdp_10),
                           x = gdp_90,
                           xend = gdp_10),
  colour = &quot;#3E39CD&quot;, size = 1,
  colour_x = &quot;#BD274A&quot;, colour_xend = &quot;#60AF1A&quot;)+
  scale_x_continuous(labels = comma)+ # separando por vírgula (&#39;000)
  theme_graph()+
  labs(title = &quot;20 countries with the highest per capita GDP variation&quot;,
       subtitle = &quot;Group: Up Middle income (GDP per capita &lt;= 45.000 US$ (2010))&quot;)</code></pre>
<p><img src="/posts/2019-11-30-accessing-world-bank-database-using-R_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<pre class="r"><code>df_gdp_pc_2 %&gt;%
  select(date,
         country,
         value) %&gt;% 
  filter(date %in% c(&quot;1990&quot;,max(date))) %&gt;% 
  mutate(gdp_90 = ifelse(date == &quot;1990&quot;,value,0),
         gdp_10 = ifelse(date == &quot;2010&quot;,value,0)) %&gt;% 
  group_by(country) %&gt;% 
  summarise(gdp_90 = sum(gdp_90),
            gdp_10 = sum(gdp_10)) %&gt;% 
  filter(gdp_90 &gt; 0 &amp; gdp_10 &gt; 0) %&gt;% 
  mutate(delta = round(1-(gdp_90/gdp_10),digits = 4),
         income_range = ifelse(gdp_10 &lt;= 5000,&quot;low&quot;,
                        ifelse(gdp_10 &lt;= 15000,&quot;middle&quot;,
                        ifelse(gdp_10 &lt;= 45000,&quot;up_middle&quot;,
                        ifelse(gdp_10 &lt;= 60000,&quot;high&quot;,
                        ifelse(gdp_10 &lt;= 90000,&quot;up_high&quot;,
                        &quot;ultra_rich&quot;)))))) %&gt;% 
  filter(income_range == &quot;high&quot;) %&gt;% 
  arrange(desc(delta)) %&gt;% 
  head(20) %&gt;% 
  ggplot()+
  ggalt::geom_dumbbell(aes(y = fct_reorder(country,gdp_10),
                           x = gdp_90,
                           xend = gdp_10),
  colour = &quot;#3E39CD&quot;, size = 1,
  colour_x = &quot;#BD274A&quot;, colour_xend = &quot;#60AF1A&quot;)+
  scale_x_continuous(labels = comma)+ # separando por vírgula (&#39;000)
  theme_graph()+
  labs(title = &quot;20 countries with the highest per capita GDP variation&quot;,
       subtitle = &quot;Group: High (GDP per capita &lt;= 60.000 US$ (2010))&quot;)</code></pre>
<p><img src="/posts/2019-11-30-accessing-world-bank-database-using-R_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<pre class="r"><code>df_gdp_pc_2 %&gt;%
  select(date,
         country,
         value) %&gt;% 
  filter(date %in% c(&quot;1990&quot;,max(date))) %&gt;% 
  mutate(gdp_90 = ifelse(date == &quot;1990&quot;,value,0),
         gdp_10 = ifelse(date == &quot;2010&quot;,value,0)) %&gt;% 
  group_by(country) %&gt;% 
  summarise(gdp_90 = sum(gdp_90),
            gdp_10 = sum(gdp_10)) %&gt;% 
  filter(gdp_90 &gt; 0 &amp; gdp_10 &gt; 0) %&gt;% 
  mutate(delta = round(1-(gdp_90/gdp_10),digits = 4),
         income_range = ifelse(gdp_10 &lt;= 5000,&quot;low&quot;,
                        ifelse(gdp_10 &lt;= 15000,&quot;middle&quot;,
                        ifelse(gdp_10 &lt;= 45000,&quot;up_middle&quot;,
                        ifelse(gdp_10 &lt;= 60000,&quot;high&quot;,
                        ifelse(gdp_10 &lt;= 90000,&quot;up_high&quot;,
                        &quot;ultra_rich&quot;)))))) %&gt;% 
  filter(income_range == &quot;up_high&quot;) %&gt;% 
  arrange(desc(delta)) %&gt;% 
  head(20) %&gt;% 
  ggplot()+
  ggalt::geom_dumbbell(aes(y = fct_reorder(country,gdp_10),
                           x = gdp_90,
                           xend = gdp_10),
  colour = &quot;#3E39CD&quot;, size = 1,
  colour_x = &quot;#BD274A&quot;, colour_xend = &quot;#60AF1A&quot;)+
  scale_x_continuous(labels = comma)+ # separando por vírgula (&#39;000)
  theme_graph()+
  labs(title = &quot;20 countries with the highest per capita GDP variation&quot;,
       subtitle = &quot;Group: Up High income (GDP per capita &lt;= 90.000 US$ (2010))&quot;)</code></pre>
<p><img src="/posts/2019-11-30-accessing-world-bank-database-using-R_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>Now lets see, for the same country (i.e. Brazil), the variety of GDP indicators counted by the World Bank.</p>
<ol style="list-style-type: decimal">
<li><p>GDP per capita (PPP)</p></li>
<li><p>GDP per Capita (LCU - Local currency unit)</p></li>
<li><p>GDP per Capita (2010 US$)</p></li>
<li><p>GDP per Capita (current US$)</p></li>
</ol>
<p>When you want bring more than one indicator, you just have to list then as a list. See the following code as an example:</p>
<pre class="r"><code>df_gdp_pc_3 &lt;- wbstats::wb(indicator = c(&quot;NY.GDP.PCAP.PP.CD&quot;,
                                         &quot;NY.GDP.PCAP.CN&quot;,
                                         &quot;NY.GDP.PCAP.KD&quot;,
                                         &quot;NY.GDP.PCAP.CD&quot;),
                           country = &quot;BRA&quot;,mrv = 10)</code></pre>
<p>Lets plot a time series of these 4 indicators.</p>
<pre class="r"><code>df_gdp_pc_3 %&gt;% 
  ggplot(aes(x=date,y=value,group=indicator,color=indicator))+
  geom_line(size=1)+
  geom_point()+
  scale_y_continuous(labels = scales::comma)+
  theme_graph()+
  labs(title = &quot;Brazil GDP in 4 different visions&quot;,
       x = &quot;&quot;,
       y = &quot;&quot;)</code></pre>
<p><img src="/posts/2019-11-30-accessing-world-bank-database-using-R_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>Continuing with the analysis about economic indicators of the latin america region, lets see the government debt in proportion of the GDP. For this indicator, I’ll bring the last 20 result set starting from the most recent, using the “mrv” parameter.</p>
<pre class="r"><code>df_gov_debt &lt;- wbstats::wb(country = &quot;countries_only&quot;,
                           indicator = &quot;GC.DOD.TOTL.GD.ZS&quot;,
                           mrv = 20)</code></pre>
<p>We can see which latin america country increased its spenditures in proportion of the GDP more. This can occur by an increase in spenditures or by a decrease in the GDP.</p>
<pre class="r"><code>df_gov_debt %&gt;% 
  filter(country %in% c(&quot;Brazil&quot;,&quot;Chile&quot;,&quot;Ecuador&quot;,&quot;Venezuela, RB&quot;,
                        &quot;Colombia&quot;,&quot;Peru&quot;,&quot;Argentina&quot;,&quot;Bolivia&quot;,
                        &quot;Uruguay&quot;,&quot;Paraguay&quot;)) %&gt;% 
  select(country,
         date,
         value) %&gt;% 
  mutate(country = factor(country,
                          levels = c( &quot;Brazil&quot;,
                                      &quot;Bolivia&quot;,
                                      &quot;Colombia&quot;,
                                      &quot;Uruguay&quot;,
                                      &quot;Peru&quot;))) %&gt;% # reordenando os países
  ggplot(aes(x=date,y=value,group=country,color=country))+
  geom_line(size=1)+
  geom_point()+
  theme_graph()+
  labs(title = &quot;Share of debt over GDP&quot;,
       subtitle = &quot;&quot;,
       x = &quot;&quot;,
       y = &quot;&quot;)</code></pre>
<p><img src="/posts/2019-11-30-accessing-world-bank-database-using-R_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>Now lets see which latin america country have the greatest share of export and import over GDP. This indicator is interesting because it shows the comercial opennes of a country. We can note that Brazil and Argentina are the closest countries of the region.</p>
<pre class="r"><code>wbstats::wb(indicator = &quot;NE.TRD.GNFS.ZS&quot;,country = &quot;countries_only&quot;) %&gt;% 
  filter(country %in% c(&quot;Brazil&quot;,&quot;Chile&quot;,&quot;Ecuador&quot;,&quot;Venezuela, RB&quot;,
                        &quot;Colombia&quot;,&quot;Peru&quot;,&quot;Argentina&quot;,&quot;Bolivia&quot;,
                        &quot;Uruguay&quot;,&quot;Paraguay&quot;)) %&gt;%
  select(country,
         date,
         value) %&gt;% 
  mutate(country = fct_reorder(country,value,.desc = T)) %&gt;% 
  ggplot(aes(x=date,y=value,group=country,color=country))+
  geom_line(size=1,alpha=.6)+
  geom_point()+
  scale_x_discrete(breaks = c(seq(1970,2020,by = 10)))+
  theme_graph()+
  labs(title = &quot;% Exp + Imp over GDP&quot;,
       x = &quot;&quot;,
       y = &quot;&quot;)</code></pre>
<p><img src="/posts/2019-11-30-accessing-world-bank-database-using-R_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>And to finish, lets see the Gini index.</p>
<pre class="r"><code>wbstats::wb(indicator = &quot;SI.POV.GINI&quot;,country = &quot;countries_only&quot;,mrv = 10) %&gt;% 
  filter(country %in% c(&quot;Brazil&quot;,&quot;Chile&quot;,&quot;Ecuador&quot;,&quot;Venezuela, RB&quot;,
                        &quot;Colombia&quot;,&quot;Peru&quot;,&quot;Argentina&quot;,
                        &quot;Bolivia&quot;,&quot;Uruguay&quot;,&quot;Paraguay&quot;)) %&gt;%
  select(country,
         date,
         value) %&gt;% 
  mutate(country = fct_reorder(country,value,.desc = T)) %&gt;% 
  ggplot(aes(x=date,y=value,group=country,color=country))+
  geom_line(size=1)+
  theme_graph()+
  labs(title = &quot;Latin America Gini index&quot;,
       x = &quot;&quot;,
       y = &quot;&quot;)</code></pre>
<p><img src="/posts/2019-11-30-accessing-world-bank-database-using-R_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>That’s it, I hope that with these examples shown it became possible to understand how the “wbstats” package works. I believe that this database can be pretty useful in a variety of projects.</p>
]]></content>
        </item>
        
        <item>
            <title>Connecting R on Amazon Redshift Database</title>
            <link>/posts/2019/10/connecting-r-on-amazon-redshift-database/</link>
            <pubDate>Mon, 28 Oct 2019 00:00:00 +0000</pubDate>
            
            <guid>/posts/2019/10/connecting-r-on-amazon-redshift-database/</guid>
            <description>IntroductionIn this tutorial I’ll show a step by step on how to access Amazon Redshift Database throughout R. This task will be very useful if you prefer use R intead of the traditional Excel to execute exploratory data analysis on your company. The goal of this tutorial is to access the database from R, bring a data.frame as a result set and then create your analysis.
Step 1Dowload the JDBC driver from Amazon.</description>
            <content type="html"><![CDATA[


<div id="introduction" class="section level2">
<h2><strong>Introduction</strong></h2>
<p>In this tutorial I’ll show a step by step on how to access Amazon Redshift Database throughout R. This task will be very useful if you prefer use R intead of the traditional Excel to execute exploratory data analysis on your company. The goal of this tutorial is to access the database from R, bring a data.frame as a result set and then create your analysis.</p>
</div>
<div id="step-1" class="section level2">
<h2><strong>Step 1</strong></h2>
<p>Dowload the JDBC driver from Amazon. This file will be needed to allow the connection of one tool (i.e. R Studio) to the Amazon cluster that you have access. In this <a href="https://docs.aws.amazon.com/pt_br/redshift/latest/mgmt/configure-jdbc-connection.html#obtain-jdbc-url">link</a> there’s the files indicated for each version of the JDBC.</p>
<p>Ps: If at the end of the role process the database access fail, take a look on the above file that you dowloaded to see if it came corrupted. This can be caused (not likely but it can) when the dowload is made directly from R.</p>
</div>
<div id="step-2" class="section level2">
<h2><strong>Step 2</strong></h2>
<p>Inside R Studio, install and call the following packages: “rJava” and “RJDBC”.</p>
<pre class="r"><code>install.packages(&quot;rJava&quot;)
install.packages(&quot;RJDBC&quot;)

library(rJava)
library(RJDBC)</code></pre>
</div>
<div id="step-3" class="section level2">
<h2><strong>Step 3</strong></h2>
<p>Create a variable (i.e. “driver”) that will contain the JDBC file that was dowloaded on the Step 1. Use the following code for this step:</p>
<pre class="r"><code>driver &lt;- JDBC(driverClass = &quot;com.amazon.redshift.jdbc41.Driver&quot;, 
               classPath = Sys.glob(&quot;caminho do arquivo/RedshiftJDBC41-1.1.9.1009.jar&quot;), 
               identifier.quote=&quot;`&quot;)</code></pre>
</div>
<div id="step-4" class="section level2">
<h2><strong>Step 4</strong></h2>
<p>Create a variable (i.e. “db_connection”) that will indicate the information of the database to be accessed by R Studio. Use the following code for this step:</p>
<pre class="r"><code>db_connection &lt;- sprintf(&quot;jdbc:redshift://%s:%s/%s?tcpKeepAlive=true&amp;ssl=true&amp;sslfactory=com.amazon.redshift.ssl.NonValidatingFactory&quot;, 
                         &quot;host of the database&quot;, 
                         &quot;port&quot;, 
                         &quot;database name&quot;)</code></pre>
</div>
<div id="step-5" class="section level2">
<h2><strong>Step 5</strong></h2>
<p>Create a variable (i.e. “access”) that will contain the information of the database and also the user that will access the database. Use the following code for this step:</p>
<pre class="r"><code>access &lt;- dbConnect(driver, db_end, &quot;user&quot;, &quot;password&quot;)</code></pre>
<p>Ps: Note that the funcion “dbConnect” used the database access file driver, the information of the database that will be accessed and the information of the user that will access the database.</p>
</div>
<div id="step-6" class="section level2">
<h2><strong>Step 6</strong></h2>
<p>After the creation of the necessary variables, to access the database it’ll be necessary the last one created (at step 5). To access the database, the package RJDBC will be used. Some examples can be seeing on the code chunck that follows:</p>
<p>Ps: Queries run on R Studio console must by with quotes.</p>
<pre class="r"><code>RJDBC::dbGetQuery(jconn,
                  &quot;select 
                     order
                   , client
                   , sale_date 
                  from orders_tb 
                  limit 10&quot;)

RJDBC::dbGetQuery(jconn,
                  &quot;select 
                     supplier
                   , invoice 
                  from supplier.tb 
                  where 1 = 1 
                  and delivery.date = 2019-01-30 
                  limit 10&quot;)</code></pre>
</div>
<div id="step-7" class="section level2">
<h2><strong>Step 7</strong></h2>
<p>To explore the feature in depth, it’s interesting that, intead of writing the query on the R Studio console, you save your query in a file (.sql) and make R access this file and save it as a variable (i.e. “sql_file”). To do this, it’s necessary to install and call the “readr” package.</p>
<pre class="r"><code>install.packages(&quot;readr&quot;)

library(readr)

-- Saving the .sql file as a variable
sql_file &lt;- readr::read_file(&quot;path_of_the_file/script.sql&quot;)

-- Using the .sql file to access Redshift database
query_redshift &lt;- RJDBC::dbGetQuery(jconn, sql_file)</code></pre>
</div>
<div id="final-step-plus" class="section level2">
<h2><strong>Final step (plus)</strong></h2>
<p>Sometimes you can have projects that demand more than one query, thus you will need many .sql files in order to run each query. But there’s a solution to make things simpler. You can save many queries on the same .sql file and separate each query by a string (i.e. –query_1_being, –query_1_end, –query_2_begin, –query_2_end, and so on). Then, you can use regexp to split your file and create variables for each query. The regexp will access the defined query and execute the split to create the variable with just one query code. For this step, you will need to install and call the “stringr” package.</p>
<pre class="r"><code>install.packages(&quot;stringr&quot;)

library(stringr)

-- saving the .sql file as a variable
sql_syntax &lt;- readr::read_file(&quot;.sql_file_path.all_queries.sql&quot;)

-- creating one variable with the first query of the .sql file
query_1 &lt;- 
  RJDBC::dbGetQuery(jconn, 
                    substr(sql_syntax, 
                           min(stringr::str_locate(string = sql_syntax, &#39;-- query.1.begin&#39;)), 
                           max(stringr::str_locate(string = sql_syntax, &#39;-- query.1.end&#39;))))

query_2 &lt;- 
  RJDBC::dbGetQuery(jconn, 
                    substr(sql_syntax, 
                           min(stringr::str_locate(string = sql_syntax, &#39;-- query.2.begin&#39;)), 
                           max(stringr::str_locate(string = sql_syntax, &#39;-- query.2.end&#39;))))

query_3 &lt;- 
  RJDBC::dbGetQuery(jconn, 
                    substr(sql_syntax, 
                           min(stringr::str_locate(string = sql_syntax, &#39;-- query.3.begin&#39;)),
                           max(stringr::str_locate(string = sql_syntax, &#39;-- query.3.end&#39;))))</code></pre>
</div>
<div id="conclusion" class="section level2">
<h2><strong>Conclusion</strong></h2>
<p>This tutorial was aimed to show how simple it is to access Amazon Redshift database throughout R Studio. It’s an excellent alternative when you want to perform robust exploratory data analysis (where Excel will let you down).</p>
</div>
<div id="more-tutorials-on-the-subject" class="section level2">
<h2><strong>More tutorials on the subject</strong></h2>
<p><a href="https://www.progress.com/tutorials/jdbc/connecting-to-amazon-redshift-from-r-via-jdbc-driver">Connecting to Amazon Redshift from R</a></p>
<p><a href="https://www.r-bloggers.com/a-comprehensive-guide-to-connect-r-to-amazon-redshift/">A comprehensive guide to connect R to Amazon Redshift</a></p>
</div>
]]></content>
        </item>
        
        <item>
            <title>Residual analysis in econometric models</title>
            <link>/posts/2019/09/residual-analysis-in-econometric-models/</link>
            <pubDate>Thu, 05 Sep 2019 00:00:00 +0000</pubDate>
            
            <guid>/posts/2019/09/residual-analysis-in-econometric-models/</guid>
            <description>The linear regression model is highly used on the prediction of continuous variables, where is one or more independent variables and one dependent one (the one that it seeks to test an hipothesis about its behavior). This is a pretty simple model to by executed and one of the firsts to be taught in econometric classes. Although its simplicity, in order to reach reliable results, some assumptions are needed, like the following:</description>
            <content type="html"><![CDATA[


<p>The linear regression model is highly used on the prediction of continuous variables, where is one or more independent variables and one dependent one (the one that it seeks to test an hipothesis about its behavior). This is a pretty simple model to by executed and one of the firsts to be taught in econometric classes. Although its simplicity, in order to reach reliable results, some assumptions are needed, like the following:</p>
<ol style="list-style-type: lower-roman">
<li><p>Absence of multicolineatiry between independent variables</p></li>
<li><p>Absence of autocorrelation on the dependent variable</p></li>
<li><p>Absence of pattern on the behavior of the model residuals, in other words, absence of heteroscedasticity</p></li>
<li><p>Normal distribution of residuals</p></li>
</ol>
<p>Having this assumptions satisfied, the model can be executed and the generated conclusions will be reliable to allow decision making. In this post, I’ll analyse the behavior of the residuals from a linear regression model in order to validate the assumptions (iii) and (iv). For this, I’ll use a data set that presents the price of suggarcane as independent variable and the planted area of this product, that will be the dependent variable.</p>
<p>The goal of this example is to analyse, through a simple linear regression model, the suggarcane supply elasticity as a function of the suggarcane price. The hipothesis is that there’s elasticity on the supply, thus the planted area increases in responde to a price increase. But, in order to validade this existence, it’s necessary to check, using a regression model, that these two variables have correlation. Then, the assumptions (iii) and (iv) will support this conclusion.</p>
<p>For this example, I’ll utilize the following R packages:</p>
<pre class="r"><code>library(tidyverse)
library(lmtest)
library(corrplot)
library(readxl)
library(gridExtra)
library(ggthemes)

theme_graph &lt;- function(){
  theme(
    plot.title = element_text(size = 16),
    plot.subtitle = element_text(size = 12),
    plot.caption = element_text(face = &quot;italic&quot;, size = 9),
    axis.text = element_text(size = 9),
    axis.title = element_text(face = &quot;italic&quot;, size = 9),
    text = element_text(family = &quot;Times New Roman&quot;),
    strip.background = element_rect(fill = &quot;grey&quot;),
    strip.text = element_text(face = &quot;bold&quot;),
    legend.title = element_blank(),
    legend.position = &quot;bottom&quot;
  )
}
  
graph_color &lt;- &quot;#006666&quot;</code></pre>
<pre class="r"><code>dados &lt;- readxl::read_excel(&quot;C:/Users/francisco.piccolo/Desktop/R/franciscopiccolo.github.io/datasets/Econometria_exercicios/autocorrelacao_cana_de_acucar.xlsx&quot;)

# Chaging the name of the field to remove blanck spaces
dados %&gt;% 
  transmute(
    periodo = Período,
    area = Área,
    valor = `Preço da Cana de Açúcar`*100,
    log_area = log(area),
    log_valor = log(valor),
    delta_area = round((area/lag(area,1))-1,digits = 2),
    delta_log_area = round(log_area-lag(log_area,1),digits = 2),
    delta_valor = round((valor/lag(valor,1))-1,digits=2),
    delta_log_valor = round(log_valor-lag(log_valor),digits = 2),
    log_area_precicion = delta_area - delta_log_area,
    log_valor_precision = delta_valor - delta_log_valor
  ) -&gt; dados_2</code></pre>
<p>The data set of this example has 34 rows, with planted area and suggarcane price data. Both fields with log transformation (natural) included. Folliwing there’s a sample of the data set:</p>
<pre class="r"><code>dados_2[sample(nrow(dados_2),10), ] %&gt;%
    as.tibble()</code></pre>
<pre><code>## # A tibble: 10 x 11
##    periodo  area valor log_area log_valor delta_area delta_log_area delta_valor
##      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;          &lt;dbl&gt;       &lt;dbl&gt;
##  1      11    88  22.6     4.48      3.12       0.26           0.23        0.15
##  2      33   237  40.2     5.47      3.69       0.14           0.13       -0.13
##  3      22   138  28.5     4.93      3.35      -0.03          -0.04       -0.23
##  4      25    87  30.1     4.47      3.41      -0.32          -0.39       -0.07
##  5      18    91  20.5     4.51      3.02      -0.64          -1.01       -0.46
##  6      19   121  26.7     4.80      3.29       0.33           0.28        0.3 
##  7      26   124  28.8     4.82      3.36       0.43           0.35       -0.04
##  8       3    42  10.1     3.74      2.31      -0.41          -0.53       -0.12
##  9      16    99  22.1     4.60      3.09      -0.21          -0.23       -0.06
## 10      29   197  35.3     5.28      3.56       0.3            0.26       -0.13
## # ... with 3 more variables: delta_log_valor &lt;dbl&gt;, log_area_precicion &lt;dbl&gt;,
## #   log_valor_precision &lt;dbl&gt;</code></pre>
<p>The linear regression model proposed for this problem is defined by the following equation:</p>
<p><span class="math display">\[ lnY_t = \beta_0+\beta_1 (lnX_t) + U_t \]</span></p>
<p>Where:</p>
<p><span class="math inline">\(Y_t\)</span> = planted area on year t, natural log transformed</p>
<p><span class="math inline">\(X_t\)</span> = suggarcane price on year t, natural log transformed</p>
<p><span class="math inline">\(\beta_0\)</span> = Intercept</p>
<p><span class="math inline">\(\beta_1\)</span> = slope</p>
<p><span class="math inline">\(U_t\)</span> = Model residuals</p>
<p>The natural log is used to in order to have variations between periods interpreted as percentual variation. This assumption is made possible only for natural log transformations and this adjustment is needed in problems invonving elasticity, because elasticity is interpreted as a percentual variation in one variable given a percentual variation in another variable.</p>
<p>Following is an example of this property of natural log transformations. You can see that the total variation can be seen as percentual variation after the natural log transformation. For more explanations on this topic you can see <a href="https://people.duke.edu/~rnau/411log.htm">article 1</a> <a href="https://dev.to/rokaandy/logarithmic-transformation-in-linear-regression-models-why-when-3a7c">article 2</a>.</p>
<pre class="r"><code>data.frame(
    &quot;Valor&quot; = c(100,105,112,120),
    &quot;Crescimento&quot; = c(&quot;-&quot;,&quot;5.00%&quot;,&quot;6.67%&quot;,&quot;7.14%&quot;),
    &quot;Log natural&quot; = c(log(100),log(105),log(112),log(120)),
    &quot;Delta&quot; = c(&quot;-&quot;,
                  paste(round(log(105)-log(100),4)*100,&quot;%&quot;,sep = &quot;&quot;),
                  paste(round(log(112)-log(105),4)*100,&quot;%&quot;,sep = &quot;&quot;),
                  paste(round(log(120)-log(112),4)*100,&quot;%&quot;,sep = &quot;&quot;))) %&gt;%
    as.tibble()</code></pre>
<pre><code>## # A tibble: 4 x 4
##   Valor Crescimento Log.natural Delta
##   &lt;dbl&gt; &lt;fct&gt;             &lt;dbl&gt; &lt;fct&gt;
## 1   100 -                  4.61 -    
## 2   105 5.00%              4.65 4.88%
## 3   112 6.67%              4.72 6.45%
## 4   120 7.14%              4.79 6.9%</code></pre>
<p>Veja como o crescimento percentual dos valores (5.00%, 6.67% e 7.14%) ficam bem próximos do respectivo delta, que é a diferença entre o log natural do número com relação ao log natural do número anterior (e.g. 4.654 - 4.605 = 0.0488). Desta forma, se a equação estiver em logarítmo natural em ambos os lados, pode-se interpretar que a variação percentual na variável explicativa irá gerar uma variação percentual de <span class="math inline">\(\beta_1\)</span> na variável dependente.</p>
<p>It becomes clear that the percentual values of 5.00%, 6.67% and 7.14% are pretty close to the value of the delta field, that represents the differente between the natural log of the number and the natural log of the predecessor value (e.g. 4.654 - 4.605 = 0.0488).</p>
<p>Ao tentar criar esta mesma tabela com outros logarítmos (e.g. base 2 ou base 10), não se alcança os mesmos resultados. Portanto, esta interpretação e transformação só faz sentido com logaritmo natural. When we try to create this same view with others log transformations (e.g. base 2 or 10), we can’t reach the same results. Therefore, this interpretation and transformation make sense only for natural log.</p>
<pre class="r"><code>data.frame(
    &quot;Valor&quot; = c(100,105,112,120),
    &quot;Crescimento&quot; = c(&quot;-&quot;,&quot;5.00%&quot;,&quot;6.67%&quot;,&quot;7.14%&quot;),
    &quot;Log natural&quot; = c(log(100,2),log(105,2),log(112,2),log(120,2)),
    &quot;Delta&quot; = c(&quot;-&quot;,
                  paste(round(log(105,2)-log(100,2),4)*100,&quot;%&quot;,sep = &quot;&quot;),
                  paste(round(log(112,2)-log(105,2),4)*100,&quot;%&quot;,sep = &quot;&quot;),
                  paste(round(log(120,2)-log(112,2),4)*100,&quot;%&quot;,sep = &quot;&quot;))) %&gt;% 
    as.tibble()</code></pre>
<pre><code>## # A tibble: 4 x 4
##   Valor Crescimento Log.natural Delta
##   &lt;dbl&gt; &lt;fct&gt;             &lt;dbl&gt; &lt;fct&gt;
## 1   100 -                  6.64 -    
## 2   105 5.00%              6.71 7.04%
## 3   112 6.67%              6.81 9.31%
## 4   120 7.14%              6.91 9.95%</code></pre>
<pre class="r"><code>data.frame(
    &quot;Valor&quot; = c(100,105,112,120),
    &quot;Crescimento&quot; = c(&quot;-&quot;,&quot;5.00%&quot;,&quot;6.67%&quot;,&quot;7.14%&quot;),
    &quot;Log natural&quot; = c(log(100,10),log(105,10),log(112,10),log(120,10)),
    &quot;Delta&quot; = c(&quot;-&quot;,
                  paste(round(log(105,10)-log(100,10),4)*100,&quot;%&quot;,sep = &quot;&quot;),
                  paste(round(log(112,10)-log(105,10),4)*100,&quot;%&quot;,sep = &quot;&quot;),
                  paste(round(log(120,10)-log(112,10),4)*100,&quot;%&quot;,sep = &quot;&quot;))) %&gt;% 
    as.tibble()</code></pre>
<pre><code>## # A tibble: 4 x 4
##   Valor Crescimento Log.natural Delta
##   &lt;dbl&gt; &lt;fct&gt;             &lt;dbl&gt; &lt;fct&gt;
## 1   100 -                  2    -    
## 2   105 5.00%              2.02 2.12%
## 3   112 6.67%              2.05 2.8% 
## 4   120 7.14%              2.08 3%</code></pre>
<p>Now that we understand this property of natural log, it’s possible to validate this property on the data set that will be used on the regression model proposed, for the suggarcane price and suggarcane area planted. The delta_area and delta_value fields presents the percentual variation of one period to the preceding. At delta_log_value and delta_log_area fields is calculated the difference between one period with the preceding and the fields log_area_precision and log_value_precision calculate the difference between delta_area with delta_log_area and delta_value with delta_log_value. The lower these two values, stronger is the property of the natural log transformation explained before. The following table will show the results:</p>
<pre class="r"><code>dados_2</code></pre>
<pre><code>## # A tibble: 34 x 11
##    periodo  area valor log_area log_valor delta_area delta_log_area delta_valor
##      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;          &lt;dbl&gt;       &lt;dbl&gt;
##  1       1    29  7.53     3.37      2.02      NA             NA          NA   
##  2       2    71 11.5      4.26      2.44       1.45           0.9         0.53
##  3       3    42 10.1      3.74      2.31      -0.41          -0.53       -0.12
##  4       4    90 11.0      4.50      2.40       1.14           0.76        0.09
##  5       5    72 11.0      4.28      2.39      -0.2           -0.22       -0.01
##  6       6    57 13.2      4.04      2.58      -0.21          -0.23        0.21
##  7       7    44 14.2      3.78      2.65      -0.23          -0.26        0.07
##  8       8    61 21.0      4.11      3.04       0.39           0.33        0.48
##  9       9    60 18.8      4.09      2.94      -0.02          -0.02       -0.1 
## 10      10    70 19.6      4.25      2.98       0.17           0.15        0.04
## # ... with 24 more rows, and 3 more variables: delta_log_valor &lt;dbl&gt;,
## #   log_area_precicion &lt;dbl&gt;, log_valor_precision &lt;dbl&gt;</code></pre>
<p>After this explanation, we can continue with the regression model development. The variables will always be presented with the natural log transformation applied. The following graph shows the behavior of the studied variables and the regression line.</p>
<pre class="r"><code>dados_2 %&gt;% 
  ggplot(aes(x=log_area,y=log_valor))+
  geom_point()+
  geom_smooth(method = &quot;lm&quot;,se = F, lty = 2, color = &quot;dark orange&quot;)+
  theme_graph()+
  labs(title = &quot;Area planted and suggarcane price relation&quot;,
       subtitle= &quot;There&#39;s an elasticity &quot;,
       x = &quot;Planted area (ln)&quot;,
       y = &quot;Market price (ln)&quot;)</code></pre>
<p><img src="/posts/2019-09-05-residual-analysis-in-econometric-models_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>The variable shows linear correlation, meaning that there’s supply elasticity. Following is the summary of the regression model:</p>
<pre class="r"><code>model &lt;- lm(log_area~log_valor,data = dados_2)</code></pre>
<pre class="r"><code>summary(model)</code></pre>
<pre><code>## 
## Call:
## lm(formula = log_area ~ log_valor, data = dados_2)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.65076 -0.18823 -0.03096  0.24914  0.60492 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   1.6416     0.3534   4.645 5.56e-05 ***
## log_valor     0.9706     0.1106   8.773 5.03e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.3088 on 32 degrees of freedom
## Multiple R-squared:  0.7063, Adjusted R-squared:  0.6972 
## F-statistic: 76.97 on 1 and 32 DF,  p-value: 5.031e-10</code></pre>
<p>The regression equation generated by the model is defined as: <span class="math inline">\(lnY_t = 1.64 + 0.97 (lnX_t) + U_t\)</span></p>
<p>This equation indicates that the planted area of suggarcane would be of <span class="math inline">\(e^{1.64} = 5.15\)</span> (ha) if the price was 0. As the price increase in 1%, the impact on the planted area will be of 0.97%.</p>
<p>The r² reach 70.6%, but this isn’t enough to make conclusions about the model. Its necessary to analyse the model premissed about the residuals to ensure that the model is reliable.</p>
<pre class="r"><code>residual &lt;- residuals(model)</code></pre>
<pre class="r"><code>df &lt;- cbind(dados_2, residual)</code></pre>
<p>The next graph shows the residuals distribution in order to validate if they’re normally distributed. Both histogram and quantil-quantil plot are good choices to validate this assumption.</p>
<pre class="r"><code>df %&gt;% 
  ggplot(aes(x=residual))+
  geom_histogram(binwidth = .05,alpha=.4,fill=&quot;dark orange&quot;)+
  theme_graph()+
  labs(title = &quot;Histograma dos resíduos&quot;,
       subtitle = &quot;Aparente normalidade dos dados&quot;,
       x = &quot;&quot;,
       y = &quot;&quot;)</code></pre>
<p><img src="/posts/2019-09-05-residual-analysis-in-econometric-models_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<pre class="r"><code>df %&gt;% 
  ggplot(aes(sample=residual))+
  geom_qq()+
  theme_graph()+
  labs(title = &quot;QQ-Plot dos resíduos&quot;,
       subtitle = &quot;Corrobora a suposta normalidade dos dados&quot;,
       x = &quot;&quot;,
       y = &quot;&quot;)</code></pre>
<p><img src="/posts/2019-09-05-residual-analysis-in-econometric-models_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>Despite the graph visualization being a good bet to analyse departure from normality, it’s also important to perform formal tests like Durbin-Watson, Breusch-Godfrey and Ljung-Box Qtest. The Durbin-Watson (DW) will be the first performed:</p>
<pre class="r"><code>lmtest::dwtest(model)</code></pre>
<pre><code>## 
##  Durbin-Watson test
## 
## data:  model
## DW = 1.2912, p-value = 0.009801
## alternative hypothesis: true autocorrelation is greater than 0</code></pre>
<p>The DW value was of 1.2912 and this value will be used to generate conclusions for the test. As well as the DW value, its necessary to have the DL and DU intervals that will be compared with the DW value. The DL and DU values can be found at this <a href="http://www.portalaction.com.br/analise-de-regressao/33-diagnostico-de-independencia">table</a>. To find DL and DU values at this table, take the number of points of your data set (n = 33), the significance level (i.e. 0.05) and the degrees of freedom (i.e. 1), then we have:</p>
<p><strong>DL</strong> = 1.35</p>
<p><strong>DU</strong> = 1.49</p>
<p>With a DW of 1.2912, above 0 and under the DL value, we can conclude that the residuals are independent. Thus, we can ensure that residuals are both normally distributed and independent, then the model is reliable on what it shows (there’s elasticity on the suggarcane supply given a price variation).</p>
]]></content>
        </item>
        
    </channel>
</rss>
