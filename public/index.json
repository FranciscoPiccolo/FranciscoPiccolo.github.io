[{"authors":null,"categories":null,"content":"Atuo na área de Inteligência de Negócios (aka BI) e análise de dados desde 2015, realizando consultas em banco de dados, desenvolvimento de dashboards em ferramentas de visualização, monitoramento de data warehouse, desenvolvimento de ETLs e condução de estudos ad-hoc com uso de ferramentas estatísticas (R/R-Studio).\nEspecialidades:\n Data Warehouse: Redshift, Athena e SQL Server Data Viz: Tableau, Sisense e Qlik View Estudos ad-hoc: R Notebooks  ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://francisco.piccolo.com/author/francisco-piccolo/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/francisco-piccolo/","section":"authors","summary":"Atuo na área de Inteligência de Negócios (aka BI) e análise de dados desde 2015, realizando consultas em banco de dados, desenvolvimento de dashboards em ferramentas de visualização, monitoramento de data warehouse, desenvolvimento de ETLs e condução de estudos ad-hoc com uso de ferramentas estatísticas (R/R-Studio).","tags":null,"title":"Francisco Piccolo","type":"authors"},{"authors":null,"categories":null,"content":"\r\rO modelo de regressão linear é bastante usado na predição de variáveis contínuas, onde há uma ou mais variáveis independentes buscando mapear o comportamento de uma variável dependente. O modelo é bastante simples e lembro ser um dos primeiros a ser ensinado nas aulas de econometria. Porém, apesar de sua simplicidade, é preciso se atentar a alguns detalhes sobre suas premissas para que os resultados deste modelo possam ser usados para a tomada de decisão.\nAbaixo vou listar algumas das premissas da regressão linear:\nAusência de multicolinearidade entre as variáveis independentes.\n\rAusência de autocorrelação na variável dependente.\n\rAbsence of pattern on the behavior of the model residuals, in other words, absence of heteroscedasticity.\n\rAusência de padrão no comportamento dos resíduos do modelo, ou seja, ausência de heterocedasticidade.\n\rResíduos se distribuem de acordo com uma distribuição normal.\n\r\rTendo estas premissas atendidas, o modelo pode gerar conclusões confiáveis. Neste post eu vou desenvolver alguns modelos de regressão linear para testar as premissas iii e iv que tratam dos resíduos, para ver alguns casos práticos.\nPara começar, vamos trazer os pacotes necessários para execução das funções no R:\nlibrary(tidyverse)\rlibrary(lmtest)\rlibrary(corrplot)\rlibrary(readxl)\rTambém vou criar uma função para facilitar a padronização dos gráficos que serão gerados.\nExemplo 1: Elasticidade preço x oferta na produção de cana de açúcar.\rEste exemplo foi passado na minha aula de econometria em 2017. Na época o exercício foi realizado com o software EViews, por sorte eu guardei os dados e agora posso refazer o problema com mais facilidade com o uso do R.\nNo exercício, há a variável independente (X) sendo o preço da cana de açúcar e a variável dependente (Y) sendo a área plantada de cana de açúcar (representando uma proxy para a oferta do produto). O objetivo deste modelo é tentar quantificar a elasticidade da oferta em função do preço, ou seja, quantificar quão sensível é a oferta da cana de açúcar quando ocorre uma variações em seu preço. Os dados deste exercício estão no meu repositório do Github, vamos trazê-los com o comando abaixo, salvando-os na variável df (a.k.a data.frame):\ndf \u0026lt;- read.csv(file = \u0026quot;https://raw.githubusercontent.com/FranciscoPiccolo/franciscopiccolo.github.io/master/datasets/2019-09-05-residual_analysis_on_linear_regression_models/dataset_1.csv\u0026quot;, sep = \u0026quot;;\u0026quot;, dec = \u0026quot;,\u0026quot;)\rdim(df)\r## [1] 34 3\rCom a função dim podemos ver a dimensão deste dataset, com 34 registros e 3 colunas.\nThe data set for this example has 34 rows, with planted area and suggarcane price fields. Vamos ver uma amostra dos dados.\ndf[sample(nrow(df),5), ] %\u0026gt;%\ras_tibble()\r## # A tibble: 5 x 3\r## period area price\r## \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 22 138 0.285\r## 2 34 235 0.392\r## 3 32 208 0.463\r## 4 25 87 0.301\r## 5 9 60 0.188\rO modelo de regressão linear para este cenário será desenvolvido de acordo com a fórmula abaixo:\n\\[ lnY_t = \\beta_0+\\beta_1 (lnX_t) + \\mu_t \\]\nOnde:\n\\(Y_t\\) = Área plantada após a transformação com log natural (e)\n\\(X_t\\) = Preço da cana de açúcar também após a transformação com log natural\n\\(\\beta_0\\) = Intercepto\n\\(\\beta_1\\) = Inclinação\n\\(\\mu_t\\) = Resíduos\nOs dados precisam ter a aplicação do log natural, pois esta transformação faz com que as variações entre os períodos possam ser interpretadas como variações percentuais, e isso é necessário por conta de que a elasticidade é quantificada em termos percentuais. Esta característica ocorre apenas na transformação com logarítmo natural, se a transformação fosse feita com outros logs, a interpretação não seria válida.\nO gráfico abaixo irá mostrar o comportamento das variáveis do dataset, bem como a curva de regressão linear, antes de aplicar a transformação log natural.\ndf %\u0026gt;% ggplot()+\rgeom_point(mapping = aes(x = price, y = area), shape = 2)+\rgeom_smooth(mapping = aes(x = price, y = area), method = \u0026quot;lm\u0026quot;, formula = y ~ x, se = F, lty = 2,\rcolor = \u0026quot;dark orange\u0026quot;)+\rtheme_graph()+\rlabs(title = \u0026quot;Gráfico de dispersão das variáveis\u0026quot;,\rx = \u0026quot;Preço da Cana de Açúcar\u0026quot;,\ry = \u0026quot;Área Plantada\u0026quot;)\rPodemos ver que há uma relação entre o preço do produto e sua oferta. Agora vamos aplicar o log natural no modelo de regressão. Para isso, o R nos fornece duas opções:\n\rAjustar as variáveis no dataset e construir o modelo usando as variáveis ajustadas.\n\rConstruir o modelo e indicar “dentro dele” que é necessário fazer a transformação antes de computar os resultados.\n\r\rVamos ver na prática como cada opção pode ser usada. O resultado final será idêntico.\nPrimeiro vou criar duas variáveis com os resultados dos dois métodos:\n# Método 1, criando novos campos no dataset com a transformação log (e)\rfirst_method \u0026lt;- df %\u0026gt;% mutate(area_log = log(area),\rprice_log = log(price)) %\u0026gt;% lm(formula = area_log ~ price_log)\rsecond_method \u0026lt;- df %\u0026gt;% lm(formula = log(area) ~ log(price))\rCom as duas variáveis criadas, vamos criar uma tabela comparando os principais resultados dos modelos:\ndata.frame(\u0026quot;1º Método\u0026quot; = c(first_method$coefficients),\r\u0026quot;2º Método\u0026quot; = c(second_method$coefficients))\r## X1º.Método X2º.Método\r## (Intercept) 6.1113284 6.1113284\r## price_log 0.9705823 0.9705823\rConforme indicado, ambos os métodos geram o mesmo valor. Eu prefiro o segundo, que exige menos linhas de código. Com base nos coeficientes estimados, temos a seguinte equação:\n\\[\\hat{Y} = 1.6416 + 0.9706X_1 + \\mu\\]\nO resultado é estatisticamente significativo, visto que tanto o intercepto quanto a inclinação apresentam um valor-p baixo. Veja abaixo estes valores bem como o R².\nsecond_method %\u0026gt;% summary()\r## ## Call:\r## lm(formula = log(area) ~ log(price), data = .)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -0.65076 -0.18823 -0.03096 0.24914 0.60492 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 6.1113 0.1686 36.254 \u0026lt; 2e-16 ***\r## log(price) 0.9706 0.1106 8.773 5.03e-10 ***\r## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## Residual standard error: 0.3088 on 32 degrees of freedom\r## Multiple R-squared: 0.7063, Adjusted R-squared: 0.6972 ## F-statistic: 76.97 on 1 and 32 DF, p-value: 5.031e-10\rApesar destes dados mostrarem que a reta se ajustou bem aos dados e que o modelo consegue explicar ~70% da variação na variável dependente, é preciso anda analisar os resíduos para poder ter confiança no resultado para fazer projeções. No gráfico abaixo, vamos ver como se distribui os resíduos do modelo.\nmodel_residuals \u0026lt;- data.frame(values = second_method$residuals)\rEu opto primeiro por analisar um histograma dos reísduos, pois ele indicará se a distribuição se assemelha a uma distribuição normal. Vamos ver isso no gráfico abaixo.\n# Histogram\rmodel_residuals %\u0026gt;% ggplot()+\rgeom_histogram(mapping = aes(x = values), fill = \u0026quot;steel blue\u0026quot;)+\rtheme_graph()+\rlabs(title = \u0026quot;Distribuição dos Resíduos\u0026quot;,\rx = \u0026quot;\u0026quot;,\ry = \u0026quot;\u0026quot;)\rAparentemente os resíduos se distribuem normalmente. Outro gráfico interessante para analisar é o q-q plot, que também indicará quão parecido com a distribuição normal é a distribuição de uma variável.\n# q-q plot\rmodel_residuals %\u0026gt;% ggplot()+\rgeom_qq(mapping = aes(sample = values))+\rlabs(title = \u0026quot;Residuals\u0026#39; Q-Q plot\u0026quot;,\rx = \u0026quot;\u0026quot;,\ry = \u0026quot;\u0026quot;)\rEste gráfico também aponta para a ideia de resíduos normalmente distribuídos. Apesar de estes métodos serem bons e práticos, as vezes é necessário usar métodos formais para gerar alguma conclusão. Para validação da independência no comportamento dos resíduos pode-se usar o teste Durbin Watson. O código abaixo realiza este teste.\n# Necessário instalar e chamar o pacote \u0026#39;lmtest\u0026#39;\rlmtest::dwtest(df %\u0026gt;% lm(formula = log(area) ~ log(price)))\r## ## Durbin-Watson test\r## ## data: df %\u0026gt;% lm(formula = log(area) ~ log(price))\r## DW = 1.2912, p-value = 0.009801\r## alternative hypothesis: true autocorrelation is greater than 0\rO resultado do teste foi de 1.2912, mas apenas com este valor não é possível fazer uma conclusão. Em conjunto com este valor, é preciso saber os valores limiares DL e DU, que podem ser encontrados nesta tabela. Para encontrar os valores com esta tabela, basta saber o número de observações no dataset (i.e. n = 33), o nível de significância do teste (i.e. 0.05) e os graus de liberdade (i.e. 1). Com isso, tem-se:\nDL = 1.35\nDU = 1.49\nTendo DW igual a 1.2912, acima de 0 e abaixo de DL, pode-se concluir que os resíduos são independentes.\nCom isso, podemos concluir que de fato o modelo é confiável para realizar projeções, pois tanto os gráficos quanto o teste formal indicam que as premissas (iii) e (iv) estão sendo atendidas, como como as outras premissas. Desta forma, podemos concluir que há elasticidade na oferta de cana de açúcar com relação ao seu preço.\n\r","date":1568073600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568073600,"objectID":"63ffe4d20aed57a7f4aac9f30592f5d4","permalink":"https://francisco.piccolo.com/post/2019-09-05-residual-analysis-in-econometric-models/","publishdate":"2019-09-10T00:00:00Z","relpermalink":"/post/2019-09-05-residual-analysis-in-econometric-models/","section":"post","summary":"O modelo de regressão linear é bastante usado na predição de variáveis contínuas, onde há uma ou mais variáveis independentes buscando mapear o comportamento de uma variável dependente. O modelo é bastante simples e lembro ser um dos primeiros a ser ensinado nas aulas de econometria.","tags":null,"title":"Análise de Resíduos em Modelos de Regressão Linear","type":"post"}]