labs(title = "Brand concentration index segmented by customer type",
x = "",
y = "Brand concentration index")
query_19$sale_date <- lubridate::ymd(query_19$sale_date)
query_19 %>%
ggplot()+
geom_line(mapping = aes(x = sale_date, y = avg_brand_share_sliper), color = graph_color)+
scale_y_continuous(labels = scales::percent)+
facet_wrap(~brand)+
labs(title = "Sliper share on selected brand gtv",
subtitle = "Only slipers with more than R$100.000 in GTV canceled on the past three years",
x = "",
y = "% GTV purchased by Slipers",
caption = "20 days moving average")
query_19 %>%
head()
dw_inf <- data.frame(read.table("C:/Users/francisco.piccolo/Desktop/R/Redshift_access/dw_prod_access.txt",sep=" "))
sprintf <- as.character(dw_inf[2,2])
host <- as.character(dw_inf[3,2])
port <- as.character(dw_inf[4,2])
dw <- as.character(dw_inf[5,2])
user <- as.character(dw_inf[6,2])
password <- as.character(dw_inf[7,2])
driver <- JDBC(driverClass = 'com.amazon.redshift.jdbc41.Driver', classPath = Sys.glob("C:/Users/francisco.piccolo/Documents/R/Redshift_JDBC/RedshiftJDBC41-1.1.9.1009.jar"), identifier.quote="`")
db_end <- sprintf(sprintf, host, port, dw)
jconn <- dbConnect(driver, db_end, user, password)
sql_syntax <- readr::read_file('C:/Users/francisco.piccolo/Desktop/R/04.Queries/cancel_rate/cancelation_squad.sql')
query_19 <- RJDBC::dbGetQuery(jconn,substr(sql_syntax,min(stringr::str_locate(string=sql_syntax,'-- query_19_begin')),max(stringr::str_locate(string=sql_syntax,'-- query_19_end'))))
readr::write_rds(query_18,"C:/Users/francisco.piccolo/Desktop/R/02.Data_bases/cancelation_squad/query_19.RDS")
query_19$sale_date <- lubridate::ymd(query_19$sale_date)
query_19 %>%
head()
query_19 %>%
ggplot()+
geom_line(mapping = aes(x = sale_date, y = avg_cancel_rate), color = graph_color)+
scale_y_continuous(labels = scales::percent)+
facet_wrap(~brand)+
labs(title = "Sliper share on selected brand gtv",
subtitle = "Only slipers with more than R$100.000 in GTV canceled on the past three years",
x = "",
y = "% GTV purchased by Slipers",
caption = "20 days moving average")
scale_y_continuous(labels = scales::percent)+
facet_wrap(~brand)+
labs(title = "Sliper share on selected brand gtv",
subtitle = "Only slipers with more than R$100.000 in GTV canceled on the past three years",
x = "",
y = "% GTV purchased by Slipers",
caption = "20 days moving average")
query_19 %>%
ggplot()+
geom_line(mapping = aes(x = sale_date, y = avg_cancel_rate), color = graph_color, size = line_size)+
geom_hline(yintercept = .20, lty = 2, color = "dark yellow")+
scale_y_continuous(labels = scales::percent)+
facet_wrap(~brand)+
labs(title = "Sliper share on selected brand gtv",
subtitle = "Only slipers with more than R$100.000 in GTV canceled on the past three years",
x = "",
y = "% GTV purchased by Slipers",
caption = "20 days moving average")
query_19 %>%
ggplot()+
geom_line(mapping = aes(x = sale_date, y = avg_cancel_rate), color = graph_color, size = line_size)+
geom_hline(yintercept = .20, lty = 2, color = "dark orange")+
scale_y_continuous(labels = scales::percent)+
facet_wrap(~brand)+
labs(title = "Sliper share on selected brand gtv",
subtitle = "Only slipers with more than R$100.000 in GTV canceled on the past three years",
x = "",
y = "% GTV purchased by Slipers",
caption = "20 days moving average")
sql_syntax <- readr::read_file('C:/Users/francisco.piccolo/Desktop/R/04.Queries/cancel_rate/cancelation_squad.sql')
query_19 <- RJDBC::dbGetQuery(jconn,substr(sql_syntax,min(stringr::str_locate(string=sql_syntax,'-- query_19_begin')),max(stringr::str_locate(string=sql_syntax,'-- query_19_end'))))
readr::write_rds(query_19,"C:/Users/francisco.piccolo/Desktop/R/02.Data_bases/cancelation_squad/query_19.RDS")
query_18 <- RJDBC::dbGetQuery(jconn,substr(sql_syntax,min(stringr::str_locate(string=sql_syntax,'-- query_18_begin')),max(stringr::str_locate(string=sql_syntax,'-- query_18_end'))))
readr::write_rds(query_18,"C:/Users/francisco.piccolo/Desktop/R/02.Data_bases/cancelation_squad/query_18.RDS")
query_19$sale_date <- lubridate::ymd(query_19$sale_date)
query_19 %>%
ggplot()+
geom_line(mapping = aes(x = sale_date, y = avg_cancel_rate), color = graph_color, size = line_size)+
geom_hline(yintercept = .20, lty = 2, color = "dark orange")+
scale_y_continuous(labels = scales::percent)+
facet_wrap(~brand)+
labs(title = "Selected brands cancelation rate",
subtitle = "Only slipers with more than R$100.000 in GTV canceled on the past three years",
x = "",
y = "% GTV purchased by Slipers",
caption = "20 days moving average")
query_19 %>%
ggplot()+
geom_line(mapping = aes(x = sale_date, y = avg_share_sliper), color = graph_color, size = line_size)+
geom_hline(yintercept = .20, lty = 2, color = "dark orange")+
scale_y_continuous(labels = scales::percent)+
facet_wrap(~brand)+
labs(title = "Selected brands cancelation rate",
subtitle = "Only slipers with more than R$100.000 in GTV canceled on the past three years",
x = "",
y = "% GTV purchased by Slipers",
caption = "20 days moving average")
query_9 %>%
ggplot()+
geom_point(mapping = aes(x = brand_share_normal_customer, y = brand_share_sliper), shape = 20, color = graph_color)+
geom_text(mapping = aes(x = brand_share_normal_customer, y = brand_share_sliper, label = brand), check_overlap = T, size = 2.9, nudge_y = 0.002)+
geom_abline(lty = 2, color = graph_color_3)+
scale_y_continuous(labels = scales::percent, breaks = seq(0, 15, by = 0.03))+
scale_x_continuous(labels = scales::percent, breaks = seq(0, 15, by = 0.03))+
expand_limits(x = 0.15, y = 0.15)+
theme_graph()+
labs(title = "Expenditure distribution between brands",
subtitle = "Farther from the yellow line, more concentrated is the purchase",
x = "Normal Customers expenditures",
y = "Slipers expenditures",
caption = "Last 30 days,
Retail products only")
query_19 %>%
ggplot()+
geom_line(mapping = aes(x = sale_date, y = avg_cancel_rate), color = graph_color, size = line_size)+
geom_hline(yintercept = .20, lty = 2, color = "dark orange")+
scale_y_continuous(labels = scales::percent)+
facet_wrap(~brand)+
labs(title = "Selected brands cancelation rate",
subtitle = "Only slipers with more than R$100.000 in GTV canceled on the past three years",
x = "",
y = "% GTV purchased by Slipers",
caption = "20 days moving average")
query_19 %>%
ggplot()+
geom_line(mapping = aes(x = sale_date, y = avg_share_sliper), color = graph_color, size = line_size)+
geom_hline(yintercept = .20, lty = 2, color = "dark orange")+
scale_y_continuous(labels = scales::percent)+
facet_wrap(~brand)+
labs(title = "Selected brands cancelation rate",
subtitle = "Only slipers with more than R$100.000 in GTV canceled on the past three years",
x = "",
y = "% GTV purchased by Slipers",
caption = "20 days moving average")
query_19 %>%
ggplot()+
geom_line(mapping = aes(x = sale_date, y = avg_cancel_rate), color = graph_color, size = line_size)+
geom_hline(yintercept = .20, lty = 2, color = "dark orange")+
scale_y_continuous(labels = scales::percent)+
facet_wrap(~brand)+
labs(title = "Selected brands cancelation rate",
subtitle = "Only slipers with more than R$100.000 in GTV canceled on the past three years",
x = "",
y = "% GTV purchased by Slipers",
caption = "20 days moving average")
query_19 %>%
ggplot()+
geom_point(mapping = aes(x = avg_cancel_rate, y = avg_share_sliper))
query_19 %>%
ggplot()+
geom_point(mapping = aes(x = avg_cancel_rate, y = avg_share_sliper), shape = 20)
query_19 %>%
ggplot()+
geom_point(mapping = aes(x = cancel_rate, y = share_sliper), shape = 20)
query_19 %>%
ggplot()+
geom_point(mapping = aes(x = avg_cancel_rate, y = avg_share_sliper), shape = 20)
query_19 %>%
ggplot()+
geom_line(mapping = aes(x = sale_date, y = avg_cancel_rate), color = graph_color, size = line_size)+
geom_hline(yintercept = .20, lty = 2, color = "dark orange")+
scale_y_continuous(labels = scales::percent)+
facet_wrap(~brand)+
labs(title = "Selected brands cancelation rate",
subtitle = "Only slipers with more than R$100.000 in GTV canceled on the past three years",
x = "",
y = "% GTV purchased by Slipers",
caption = "20 days moving average")
query_12$sale_date <- lubridate::ymd(query_12$sale_date)
query_12[sample(nrow(query_12),10), ]
query_12 %>%
mutate(share_blocked = round(items_qty/stock_quantity, digits = 4)) %>%
ggplot()+
geom_histogram(mapping = aes(x = share_blocked), fill = graph_color, binwidth = .05)+
scale_x_log10(labels = scales::percent)+
theme_graph()+
labs(title = "% of SKU quantity blocked by Sliper purchase",
x = "% stock blocked",
y = "SKUs")
query_12 %>%
mutate(share_blocked = round(items_qty/stock_quantity, digits = 4)) %>%
ggplot()+
geom_histogram(mapping = aes(x = share_blocked), fill = graph_color, binwidth = .05)+
scale_x_log10(labels = scales::percent)+
theme_graph()+
labs(title = "Slipers impact on SKU's inventory",
subtitle = "Same day impact",
x = "% stock blocked",
y = "SKUs")
query_12 %>%
mutate(share_blocked = round(items_qty/stock_quantity, digits = 4)) %>%
ggplot()+
geom_histogram(mapping = aes(x = share_blocked), fill = graph_color, binwidth = .05)+
scale_x_log10(labels = scales::percent)+
scale_y_continuous(labels = scales::comma)+
theme_graph()+
labs(title = "Slipers impact on SKU's inventory",
subtitle = "Same day impact",
x = "% stock blocked",
y = "SKUs")
query_16 %>%
ggplot()+
geom_line(mapping = aes(x = sale_date, y = gtv), color = graph_color, alpha = .4)+
geom_vline(xintercept = as.Date(c("2020-02-20")), lty = 2, color = "dark orange")+
scale_y_continuous(labels = scales::comma)+
facet_wrap(~customer_name, scales = "free_y")+
theme_graph()+
labs(title = "Customers that have received the contact",
x = "",
y = "GTV generated")
query_16$sale_date <- lubridate::ymd(query_16$sale_date)
query_16 %>%
ggplot()+
geom_line(mapping = aes(x = sale_date, y = gtv), color = graph_color, alpha = .4)+
geom_vline(xintercept = as.Date(c("2020-02-20")), lty = 2, color = "dark orange")+
scale_y_continuous(labels = scales::comma)+
facet_wrap(~customer_name, scales = "free_y")+
theme_graph()+
labs(title = "Customers that have received the contact",
x = "",
y = "GTV generated")
query_12 %>%
mutate(share_blocked = round(items_qty/stock_quantity, digits = 4)) %>%
ggplot()+
geom_histogram(mapping = aes(x = share_blocked), fill = graph_color, binwidth = .05)+
scale_x_log10(labels = scales::percent)+
scale_y_continuous(labels = scales::comma)+
theme_graph()+
labs(title = "Slipers impact on SKU's inventory",
subtitle = "Same day impact",
x = "% stock blocked",
y = "SKUs")
query_13 %>%
filter(sale_date >= Sys.Date()-365) %>%
mutate(sliper_type = fct_relevel(sliper_type, levels = c("light","medium","heavy","critical"))) %>%
distinct(customer_name, sliper_type) %>%
mutate(qty = 1) %>%
group_by(sliper_type) %>%
summarise(qty = sum(qty)) %>%
mutate("%_qty" = 100*(round(qty/sum(qty), digits = 4))) %>%
inner_join(gtv, by = c("sliper_type" = "sliper_type")) %>%
mutate(sliper_type = ifelse(sliper_type == "critical","critial (above 1.000.000)",
ifelse(sliper_type == "heavy","heavy (between 100.001 and 1.000.000)",
ifelse(sliper_type == "medium","medium (between 10.001 and 100.000",
ifelse(sliper_type == "light", "light (up to 10.000 of revenue generation",""))))) %>%
head()
install.packages("kableExtra")
kableExtra::kable(df)
df <- query_13 %>%
filter(sale_date >= Sys.Date()-365) %>%
mutate(sliper_type = fct_relevel(sliper_type, levels = c("light","medium","heavy","critical"))) %>%
distinct(customer_name, sliper_type) %>%
mutate(qty = 1) %>%
group_by(sliper_type) %>%
summarise(qty = sum(qty)) %>%
mutate("%_qty" = 100*(round(qty/sum(qty), digits = 4))) %>%
inner_join(gtv, by = c("sliper_type" = "sliper_type")) %>%
mutate(sliper_type = ifelse(sliper_type == "critical","critial (above 1.000.000)",
ifelse(sliper_type == "heavy","heavy (between 100.001 and 1.000.000)",
ifelse(sliper_type == "medium","medium (between 10.001 and 100.000",
ifelse(sliper_type == "light", "light (up to 10.000 of revenue generation","")))))
kableExtra::kable(df)
df <- query_13 %>%
filter(sale_date >= Sys.Date()-365) %>%
mutate(sliper_type = fct_relevel(sliper_type, levels = c("light","medium","heavy","critical"))) %>%
distinct(customer_name, sliper_type) %>%
mutate(qty = 1) %>%
group_by(sliper_type) %>%
summarise(qty = sum(qty)) %>%
mutate("%_qty" = 100*(round(qty/sum(qty), digits = 4))) %>%
inner_join(gtv, by = c("sliper_type" = "sliper_type")) %>%
mutate(sliper_type = ifelse(sliper_type == "critical","critial (above 1.000.000)",
ifelse(sliper_type == "heavy","heavy (between 100.001 and 1.000.000)",
ifelse(sliper_type == "medium","medium (between 10.001 and 100.000",
ifelse(sliper_type == "light", "light (up to 10.000 of revenue generation","")))))
kableExtra::kable(df)
knitr::kable(df)
knitr::kable(df)
df <- query_13 %>%
filter(sale_date >= Sys.Date()-365) %>%
mutate(sliper_type = fct_relevel(sliper_type, levels = c("light","medium","heavy","critical"))) %>%
distinct(customer_name, sliper_type) %>%
mutate(qty = 1) %>%
group_by(sliper_type) %>%
summarise(qty = sum(qty)) %>%
mutate("%_qty" = 100*(round(qty/sum(qty), digits = 4))) %>%
inner_join(gtv, by = c("sliper_type" = "sliper_type")) %>%
mutate(sliper_type = ifelse(sliper_type == "critical","critial (above 1.000.000)",
ifelse(sliper_type == "heavy","heavy (between 100.001 and 1.000.000)",
ifelse(sliper_type == "medium","medium (between 10.001 and 100.000",
ifelse(sliper_type == "light", "light (up to 10.000 of revenue generation","")))))
df
kable(df, "latex")
kable(df, "latex")
query_13$sale_date <- lubridate::ymd(query_13$sale_date)
query_13 %>%
filter(sale_date >= Sys.Date()-365) %>%
group_by(sliper_type) %>%
summarise(gtv = sum(gtv)) %>%
mutate("%_gtv" = 100*(round(gtv/sum(gtv), digits = 4))) %>%
select(sliper_type, "%_gtv") -> gtv
library(rJava)
library(RJDBC)
library(extrafont)
library(tidyverse)
library(gridExtra)
library(zoo)
library(knitr)
library(scales)
library(ggthemes)
library(kableExtra)
theme_graph <- function(){
theme(
plot.title = element_text(size = 10),
plot.subtitle = element_text(size = 6.5),
plot.caption = element_text(face = "italic", size = 6),
axis.text = element_text(size = 6),
axis.title = element_text(face = "italic", size = 6),
strip.background = element_rect(fill = "grey"),
strip.text = element_text(face = "bold"),
legend.title = element_blank(),
legend.position = "bottom",
legend.text = element_text(size = 5.5)
)
}
graph_color <- "#00AFA4"
graph_color_2 <- "#222222"
graph_color_3 <- "dark orange"
line_size <- .8
black_friday <- c("2019-11-29","2018-11-23","2017-11-24")
df <- query_13 %>%
filter(sale_date >= Sys.Date()-365) %>%
mutate(sliper_type = fct_relevel(sliper_type, levels = c("light","medium","heavy","critical"))) %>%
distinct(customer_name, sliper_type) %>%
mutate(qty = 1) %>%
group_by(sliper_type) %>%
summarise(qty = sum(qty)) %>%
mutate("%_qty" = 100*(round(qty/sum(qty), digits = 4))) %>%
inner_join(gtv, by = c("sliper_type" = "sliper_type")) %>%
mutate(sliper_type = ifelse(sliper_type == "critical","critial (above 1.000.000)",
ifelse(sliper_type == "heavy","heavy (between 100.001 and 1.000.000)",
ifelse(sliper_type == "medium","medium (between 10.001 and 100.000",
ifelse(sliper_type == "light", "light (up to 10.000 of revenue generation","")))))
kable(df, "latex")
kable(df)
tinytex::reinstall_tinytex()
sql_syntax <- readr::read_file("C:/Users/francisco.piccolo/Desktop/R/01.Analytics_Projects/nps_analysis_success_page_answer_rate/queries.sql")
library(rJava)
library(RJDBC)
library(tidyverse)
library(knitr)
library(scales)
theme_graph <- function(){
theme(
plot.title = element_text(size = 10),
plot.subtitle = element_text(size = 6.5),
plot.caption = element_text(face = "italic", size = 6),
axis.text = element_text(size = 6),
axis.title = element_text(face = "italic", size = 6),
strip.background = element_rect(fill = "grey"),
strip.text = element_text(face = "bold", size = 4.5),
legend.title = element_blank(),
legend.position = "bottom",
legend.text = element_text(size = 5.5)
)
}
graph_color <- "#00AFA4"
graph_color_2 <- "#222222"
graph_color_3 <- "dark orange"
line_size <- .8
black_friday <- c("2019-11-29","2018-11-23","2017-11-24")
dw_inf <- data.frame(read.table("C:/Users/francisco.piccolo/Desktop/R/Redshift_access/dw_prod_access.txt",sep = " "))
sprintf <- as.character(dw_inf[2,2])
host <- as.character(dw_inf[3,2])
port <- as.character(dw_inf[4,2])
dw <- as.character(dw_inf[5,2])
user <- as.character(dw_inf[6,2])
password <- as.character(dw_inf[7,2])
driver <- JDBC(driverClass = 'com.amazon.redshift.jdbc41.Driver', classPath = Sys.glob("C:/Users/francisco.piccolo/Documents/R/Redshift_JDBC/RedshiftJDBC41-1.1.9.1009.jar"), identifier.quote="`")
db_end <- sprintf(sprintf, host, port, dw)
jconn <- dbConnect(driver, db_end, user, password)
sql_syntax <- readr::read_file("C:/Users/francisco.piccolo/Desktop/R/01.Analytics_Projects/nps_analysis_success_page_answers_rate/queries.sql")
query_1 <- RJDBC::dbGetQuery(jconn,substr(sql_syntax,min(stringr::str_locate(string=sql_syntax,'-- query_1_begin')),max(stringr::str_locate(string=sql_syntax,'-- query_1_end'))))
readr::write_rds(query_1,"C:/Users/francisco.piccolo/Desktop/R/01.Analytics_Projects/nps_analysis_success_page_answers_rate/datasets/query_1.RDS")
query_1$sale_date <- lubridate::ymd(query_1$sale_date)
query_1 %>%
head()
query_1 %>%
ggplot()+
geom_line(mapping = aes(x = sale_date, y = answer_rate, group = country))
query_1 %>%
ggplot()+
geom_line(mapping = aes(x = sale_date, y = answer_rate, group = sotre))
query_1 %>%
ggplot()+
geom_line(mapping = aes(x = sale_date, y = answer_rate, group = store))
query_1 %>%
ggplot()+
geom_line(mapping = aes(x = sale_date, y = answer_rate, group = store, color = store))
query_1 %>%
filter(store %in% c("DAFITI BRAZIL","DAFITI ARGENTINA","DAFITI CHILE","DAFITI COLOMBIA")) %>%
ggplot()+
geom_line(mapping = aes(x = sale_date, y = answer_rate, group = store, color = store))
library(tidyverse)
library(DAAG)
library(Amelia)
library(ggthemes)
library(pander)
library(gridExtra)
library(grid)
library(plot3D)
theme_graph <- function(){
theme(
plot.title = element_text(size = 16),
plot.subtitle = element_text(size = 12),
plot.caption = element_text(face = "italic", size = 9),
axis.text = element_text(size = 9),
axis.title = element_text(face = "italic", size = 9),
text = element_text(family = "Times New Roman"),
strip.background = element_rect(fill = "grey"),
strip.text = element_text(face = "bold"),
legend.title = element_blank(),
legend.position = "bottom"
)
}
graph_color <- "#006666"
# Caminho para a pasta que contém os data sets para cada exercício
path <- "C:/Users/francisco.piccolo/Desktop/R/franciscopiccolo.github.io/base_de_dados/livro-econometria-basica-gujarati/"
tbl_2.8 <- read.table(file = paste(path,"tabela_2.8_despesa_india.txt",sep = ""),
sep = " ",
header = T,
dec = ",")
# Random sample
tbl_2.8[sample(nrow(tbl_2.8),10), ]
tbl_2.8 %>%
ggplot(aes(x = total, y = alimento))+
geom_point(color = graph_color, shape = 20)+
geom_smooth(method = "lm", se = F)+
theme_graph()+
labs(title = "Food expenditures and total expenditures",
x = "Total expenditures",
y = "Food expenditures")
tbl_2.8 %>%
ggplot(aes(x = total, y = alimento))+
geom_point(color = graph_color, shape = 20)+
geom_smooth(method = "lm", se = F, color = "dark orange")+
theme_graph()+
labs(title = "Food expenditures and total expenditures",
x = "Total expenditures",
y = "Food expenditures")
tbl_2.8 %>%
ggplot(aes(x = total, y = alimento))+
geom_point(color = graph_color, shape = 20)+
geom_smooth(method = "lm", se = F, color = "dark orange", lty = 2)+
theme_graph()+
labs(title = "Food expenditures and total expenditures",
x = "Total expenditures",
y = "Food expenditures")
df_3.18 <- data.frame(
prova_parcial = c(1,3,7,10,9,5,4,8,2,6),
prova_final = c(3,2,8,7,9,6,5,10,1,4)
)
# Sample data
df_3.18[sample(nrow(df_3.18),10), ]
# Spearman correlation
cor.test(df_3.18$prova_parcial,df_3.18$prova_final,method = "spearman") %>% pander()
library(tidyverse)
library(DAAG)
library(Amelia)
library(ggthemes)
library(pander)
library(gridExtra)
library(grid)
library(plot3D)
theme_graph <- function(){
theme(
plot.title = element_text(size = 16),
plot.subtitle = element_text(size = 12),
plot.caption = element_text(face = "italic", size = 9),
axis.text = element_text(size = 9),
axis.title = element_text(face = "italic", size = 9),
text = element_text(family = "Times New Roman"),
strip.background = element_rect(fill = "grey"),
strip.text = element_text(face = "bold"),
legend.title = element_blank(),
legend.position = "bottom"
)
}
graph_color <- "#006666"
# Caminho para a pasta que contém os data sets para cada exercício
path <- "C:/Users/francisco.piccolo/Desktop/R/franciscopiccolo.github.io/base_de_dados/livro-econometria-basica-gujarati/"
# Spearman correlation
cor.test(df_3.18$prova_parcial,df_3.18$prova_final,method = "spearman") %>% pander()
df_3.18 <- data.frame(
prova_parcial = c(1,3,7,10,9,5,4,8,2,6),
prova_final = c(3,2,8,7,9,6,5,10,1,4)
)
# Sample data
df_3.18[sample(nrow(df_3.18),10), ]
# Spearman correlation
cor.test(df_3.18$prova_parcial,
df_3.18$prova_final,
method = "spearman") %>%
pander::pander()
blogdown::serve_site()
setwd(dir = "C:/Users/francisco.piccolo/Desktop/R/franciscopiccolo.github.io")
blogdown::serve_site()
blogdown::stop_server()
blogdown::serve_site()
blogdown::stop_server()
