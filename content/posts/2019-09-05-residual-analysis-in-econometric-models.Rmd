---
title: "Análise de Resíduos em Modelos de Regressão Linear"
date: 2019-09-05
output:
  html_document:
    fig_width: 4
    fig_height: 4
    fig_align: center
    df_print: paged
---

O modelo de regressão linear é bastante usado na predição de variáveis contínuas, onde há uma ou mais variáveis independentes buscando mapear o comportamento de uma variável dependente. O modelo é bastante simples e lembro ser um dos primeiros a ser ensinado nas aulas de econometria. Porém, apesar de sua simplicidade, é preciso se atentar a alguns detalhes sobre suas premissas para que os resultados deste modelo possam ser usados para a tomada de decisão.

Abaixo vou listar algumas das premissas da regressão linear:

i) Ausência de multicolinearidade entre as variáveis independentes.

ii) Ausência de autocorrelação na variável dependente.

iii) Absence of pattern on the behavior of the model residuals, in other words, absence of heteroscedasticity.

iii) Ausência de padrão no comportamento dos resíduos do modelo, ou seja, ausência de heterocedasticidade.

iv) Resíduos se distribuem de acordo com uma distribuição normal.

Tendo estas premissas atendidas, o modelo pode gerar conclusões confiáveis. Neste post eu vou desenvolver alguns modelos de regressão linear para testar as premissas **iii** e **iv** que tratam dos resíduos, para ver alguns casos práticos.

Para começar, vamos trazer os pacotes necessários para execução das funções no R:

```{r,eval=T,include=T,echo=T,warning=F,message=F}
library(tidyverse)
library(lmtest)
library(corrplot)
library(readxl)
```

Também vou criar uma função para facilitar a padronização dos gráficos que serão gerados.

```{r,eval=T,include=T,echo=T,warning=F,message=F}
theme_graph <- function(){
  theme(
    plot.title = element_text(size = 16),
    plot.subtitle = element_text(size = 12),
    plot.caption = element_text(face = "italic", size = 9),
    axis.text = element_text(size = 9),
    axis.title = element_text(face = "italic", size = 9),
    strip.background = element_rect(fill = "grey"),
    strip.text = element_text(face = "bold"),
    legend.title = element_blank(),
    legend.position = "bottom"
  )
}
```

### **Exemplo 1: Elasticidade preço x oferta na produção de cana de açúcar.

Este exemplo foi passado na minha aula de econometria em 2017. Na época o exercício foi realizado com o software **EViews**, por sorte eu guardei os dados e agora posso refazer o problema com mais facilidade com o uso do R.

No exercício, há a variável independente (X) sendo o preço da cana de açúcar e a variável dependente (Y) sendo a área plantada de cana de açúcar (representando uma proxy para a oferta do produto). O objetivo deste modelo é tentar quantificar a elasticidade da oferta em função do preço, ou seja, quão sensível é a oferta do produto por conta de variações no preço.



The goal of this example is to analyse, through a simple linear regression model, the suggarcane supply elasticity as a function of the suggarcane price. The hipothesis is that there's elasticity on the supply, thus the planted area increases in responde to a price increase. But, in order to validade this existence, it's necessary to check, using a regression model, that these two variables have correlation. Then, the assumptions (iii) and (iv) will support this conclusion.


The data set for this example has 34 rows, with planted area and suggarcane price fields.

```{r,eval=T,include=T,echo=T,warning=F,message=F}
# Getting the dataset
dados <- readxl::read_excel("C:/Users/fppicco/Desktop/R/Github/franciscopiccolo.github.io/datasets/Econometria_exercicios/autocorrelacao_cana_de_acucar.xlsx")

# Chaging the name of the fields to remove blank spaces
dados %>% 
  transmute(period = Período,
            area = Área,
            price = `Preço da Cana de Açúcar`*100) -> df
```

Lets see a sample of this dataset.

```{r,eval=T,include=T,echo=T,warning=F,message=F}
df[sample(nrow(df),5), ] %>%
	as.tibble()
```

The linear regression model proposed for this problem is defined by the following equation:

$$ lnY_t = \beta_0+\beta_1 (lnX_t) + \mu_t $$

Where:

$Y_t$ = planted area, natural log transformed

$X_t$ = suggarcane price, natural log transformed

$\beta_0$ = intercept

$\beta_1$ = slope

$\mu_t$ = residuals

The natural log is used to in order to have variations between periods interpreted as percentual variation. This assumption is made possible only for natural log transformations and this adjustment is needed in problems invonving elasticity, because elasticity is interpreted as a percentual variation in one variable given a percentual variation in another variable.

The following graph shows the behavior of the studied variables and the regression line.

```{r,eval=T,include=T,echo=T,warning=F,message=F}
df %>% 
  ggplot()+
  geom_point(mapping = aes(x = price, y = area), shape = 20)+
  geom_smooth(mapping = aes(x = price, y = area), 
              method = "lm", 
              formula = y ~ x, 
              se = F, 
              lty = 2,
              color = "dark orange")+
  theme_graph()+
  labs(title = "Dispersion graph for the model")
```

In order to develop the model using the log transformation, there're two options:

(i) Adjust the variables on the dataset and build the normal using the new variables generated by the log scale calculation.

(ii) Use the original dataset and inform adjust the model to apply the transformation on the variables before calculating the parameters.

Lets see each one of theses methods to confirm they're equal:

**(i) **

```{r,eval=T,include=T,echo=T,warning=F,message=F}
df %>% 
  mutate(area_log = log(area),
         price_log = log(price)) %>% 
  lm(formula = area_log ~ price_log) %>% 
  summary()
```

**(ii)**

```{r,eval=T,include=T,echo=T,warning=F,message=F}
df %>% 
  lm(formula = log(area) ~ log(price)) %>% 
  summary()
```

As indicated, the two alternatives generate the same result. It's up to the researcher to choose the method. The regression model generated is:

$$\hat{Y} = 1.6416 + 0.9706X_1 + \mu$$
With both intercept and slope statistically significant given their low p-value.

The r² reach 70.6%, but this isn't enough to make conclusions about the model. Its necessary to analyse the model hypothesis about the residuals to ensure that the model is reliable. The following code return the residuals from a 'lm' model.

```{r,eval=T,include=T,echo=T,warning=F,message=F}
model_residuals <- 
  data.frame(values = df %>% 
                        lm(formula = log(area) ~ log(price)) %>% 
                        residuals())
```

The next graph shows the residuals distribution in order to validate if they're normally distributed. Both histogram and quantil-quantil plot are good choices to validate this assumption.

```{r,eval=T,include=T,echo=T,warning=F,message=F}
# Histogram
model_residuals %>% 
  ggplot()+
  geom_histogram(mapping = aes(x = values), fill = "dark orange", alpha = .5)+
  theme_graph()+
  labs(title = "Residuals Distribution",
       x = "",
       y = "")
```

```{r,eval=T,include=T,echo=T,warning=F,message=F}
# q-q plot
model_residuals %>% 
  ggplot()+
  geom_qq(mapping = aes(sample = values))+
  theme_graph()+
  labs(title = "Residuals' Q-Q plot",
       x = "",
       y = "")
```

Both graphs enforce the ideia that the model's residuals are normally distributed. But in order to make a conclusion, sometimes a formal test will be necessary. For this problem, we'll use the Durbin Watson test. This test can be performed using the following code.

```{r,eval=T,include=T,echo=T,warning=F,message=F}
lmtest::dwtest(df %>% 
                 lm(formula = log(area) ~ log(price)))
```

The test generate the value of 1.2912, but only this value isn't enough to make the conclusion. As well as the DW value, DL and DU intervals are necessary. These values can be found at this [table](http://www.portalaction.com.br/analise-de-regressao/33-diagnostico-de-independencia). In order to find them, take the number of observations of the dataset (n = 33), the significance level of your test (i.e. 0.05) and the degress of freedom (i.e. 1). Thus we have:

**DL** = 1.35

**DU** = 1.49

With a DW of 1.2912, above 0 and under the DL value, we can conclude that the residuals are independent. 

To conclude, both graphs and formal tests confirmed that the residuals are independent and then we have the hypothesis of the model satisfied, allowing inferences about the problem being studies, in this case, the elasticity of the suggarcane supply given it's price variability.
