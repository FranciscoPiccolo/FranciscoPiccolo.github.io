---
title: "Residual analysis in econometric models"
date: 2019-09-05
output:
  html_document:
    fig_width: 8.5
    fig_height: 4
---

The linear regression model is highly used on the prediction of continuous variables, where is one or more independent variables and one dependent one (the one that it seeks to test an hypothesis about its behavior). This is a pretty simple model to by executed and one of the firsts to be taught in econometric classes. Although its simplicity, in order to reach reliable results, some assumptions are needed, like the following:

i) Absence of multicolineatiry between independent variables.

ii) Absence of autocorrelation on the dependent variable.

iii) Absence of pattern on the behavior of the model residuals, in other words, absence of heteroscedasticity.

iv) Normal distribution of residuals.

Having this assumptions satisfied, the model can be executed and the generated conclusions will be reliable to allow decision making. In this post, I'll analyse the behavior of the residuals for a linear regression model in order to validate the assumptions (iii) and (iv). For this, I'll use a data set that presents the price of suggarcane as independent variable and the planted area of this product, that will be the dependent variable.

The goal of this example is to analyse, through a simple linear regression model, the suggarcane supply elasticity as a function of the suggarcane price. The hipothesis is that there's elasticity on the supply, thus the planted area increases in responde to a price increase. But, in order to validade this existence, it's necessary to check, using a regression model, that these two variables have correlation. Then, the assumptions (iii) and (iv) will support this conclusion.

For this example, I'll utilize the following R packages:

```{r,eval=T,include=T,echo=T,warning=F,message=F}
library(tidyverse)
library(lmtest)
library(corrplot)
library(readxl)

theme_graph <- function(){
  theme(
    plot.title = element_text(size = 16),
    plot.subtitle = element_text(size = 12),
    plot.caption = element_text(face = "italic", size = 9),
    axis.text = element_text(size = 9),
    axis.title = element_text(face = "italic", size = 9),
    strip.background = element_rect(fill = "grey"),
    strip.text = element_text(face = "bold"),
    legend.title = element_blank(),
    legend.position = "bottom"
  )
}
  
graph_color <- "#006666"
```

The data set for this example has 34 rows, with planted area and suggarcane price fields.

```{r,eval=T,include=T,echo=T,warning=F,message=F}
# Getting the dataset
dados <- readxl::read_excel("C:/Users/francisco.piccolo/Desktop/R/franciscopiccolo.github.io/datasets/Econometria_exercicios/autocorrelacao_cana_de_acucar.xlsx")

# Chaging the name of the fields to remove blank spaces
dados %>% 
  transmute(period = Período,
            area = Área,
            price = `Preço da Cana de Açúcar`*100) -> df
```

Lets see a sample of this dataset.

```{r,eval=T,include=T,echo=T,warning=F,message=F}
df[sample(nrow(df),5), ] %>%
	as.tibble()
```

The linear regression model proposed for this problem is defined by the following equation:

$$ lnY_t = \beta_0+\beta_1 (lnX_t) + \mu_t $$

Where:

$Y_t$ = planted area, natural log transformed

$X_t$ = suggarcane price, natural log transformed

$\beta_0$ = intercept

$\beta_1$ = slope

$\mu_t$ = residuals

The natural log is used to in order to have variations between periods interpreted as percentual variation. This assumption is made possible only for natural log transformations and this adjustment is needed in problems invonving elasticity, because elasticity is interpreted as a percentual variation in one variable given a percentual variation in another variable.

The following graph shows the behavior of the studied variables and the regression line.

```{r,eval=T,include=T,echo=T,warning=F,message=F}
df %>% 
  ggplot()+
  geom_point(mapping = aes(x = price, y = area), shape = 20)+
  geom_smooth(mapping = aes(x = price, y = area), 
              method = "lm", 
              formula = y ~ x, 
              se = F, 
              lty = 2,
              color = "dark orange")+
  theme_graph()+
  labs(title = "Dispersion graph for the model")
```

In order to develop the model using the log transformation, there're two options:

(i) Adjust the variables on the dataset and build the normal using the new variables generated by the log scale calculation.

(ii) Use the original dataset and inform adjust the model to apply the transformation on the variables before calculating the parameters.

Lets see each one of theses methods to confirm they're equal:

**(i) **

```{r,eval=T,include=T,echo=T,warning=F,message=F}
df %>% 
  mutate(area_log = log(area),
         price_log = log(price)) %>% 
  lm(formula = area_log ~ price_log) %>% 
  summary()
```

**(ii)**

```{r,eval=T,include=T,echo=T,warning=F,message=F}
df %>% 
  lm(formula = log(area) ~ log(price)) %>% 
  summary()
```

As indicated, the two alternatives generate the same result. It's up to the researcher to choose the method. The regression model generated is:

$$\hat{Y} = 1.6416 + 0.9706X_1 + \mu$$
With both intercept and slope statistically significant given their low p-value.

The r² reach 70.6%, but this isn't enough to make conclusions about the model. Its necessary to analyse the model hypothesis about the residuals to ensure that the model is reliable. The following code return the residuals from a 'lm' model.

```{r,eval=T,include=T,echo=T,warning=F,message=F}
model_residuals <- 
  data.frame(values = df %>% 
                        lm(formula = log(area) ~ log(price)) %>% 
                        residuals())
```

The next graph shows the residuals distribution in order to validate if they're normally distributed. Both histogram and quantil-quantil plot are good choices to validate this assumption.

```{r,eval=T,include=T,echo=T,warning=F,message=F}
# Histogram
model_residuals %>% 
  ggplot()+
  geom_histogram(mapping = aes(x = values), fill = "dark orange", alpha = .5)+
  theme_graph()+
  labs(title = "Residuals Distribution",
       x = "",
       y = "")
```

```{r,eval=T,include=T,echo=T,warning=F,message=F}
# q-q plot
model_residuals %>% 
  ggplot()+
  geom_qq(mapping = aes(sample = values))+
  theme_graph()+
  labs(title = "Residuals' Q-Q plot",
       x = "",
       y = "")
```

Both graphs enforce the ideia that the model's residuals are normally distributed. But in order to make a conclusion, sometimes a formal test will be necessary. For this problem, we'll use the Durbin Watson test. This test can be performed using the following code.

```{r,eval=T,include=T,echo=T,warning=F,message=F}
lmtest::dwtest(df %>% 
                 lm(formula = log(area) ~ log(price)))
```

The test generate the value of 1.2912, but only this value isn't enough to make the conclusion. As well as the DW value, DL and DU intervals are necessary. These values can be found at this [table](http://www.portalaction.com.br/analise-de-regressao/33-diagnostico-de-independencia). In order to find them, take the number of observations of the dataset (n = 33), the significance level of your test (i.e. 0.05) and the degress of freedom (i.e. 1). Thus we have:

**DL** = 1.35

**DU** = 1.49

With a DW of 1.2912, above 0 and under the DL value, we can conclude that the residuals are independent. 

To conclude, both graphs and formal tests confirmed that the residuals are independent and then we have the hypothesis of the model satisfied, allowing inferences about the problem being studies, in this case, the elasticity of the suggarcane supply given it's price variability.
