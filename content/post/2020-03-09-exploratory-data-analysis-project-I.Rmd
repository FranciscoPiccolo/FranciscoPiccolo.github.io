---
title: "Exploratory Data Analysis Project I"
output:
  html_document:
    df_print: paged
    fig_width: 8.5
    fig_height: 4.0
    code_folding: hide
---

Exploratory Data Analysis (EDA) is a technique developed by John Tukey in 1960 that aims the following goals: formulate hipothesis, generate graphs e understand patterns on the data. All these goals envision to make people aware of insights that they hadn't thought before. With this technique being created, also became alive the program language S, the predecessor of R. 

The EDA is an activity frequently made by many different professionals, that have to handle with increasingly data volumes (structured and unstructured) to answer business questions in a fastly pace. In this post I'll use a dataset that I've got in a hiring process to perform an exploratory data analysis task. The goal will be the generation of insights from this dataset to make recommendations for the alleged directors of this company.

Before we start, lets call the necessary packages for this project.
  
```{r,eval=T,include=T,echo=T,warning=F,message=F}
# Pacotes para importar
library(tidyverse)
library(gridExtra)
library(grid)
library(zoo)
library(knitr)
library(scales)
library(ggthemes)
library(zoo)
library(readxl)
library(Amelia)

theme_set(theme_bw())

theme_graph <- function(){
  theme(
    # background color
    panel.background = element_rect(fill = "white"),
    panel.grid.minor = element_blank(),
    plot.title = element_text(size = 16),
    plot.subtitle = element_text(size = 12),
    plot.caption = element_text(face = "italic", size = 9),
    axis.text = element_text(size = 9),
    axis.title = element_text(face = "italic", size = 9),
    text = element_text(family = "Times New Roman"),
    strip.background = element_rect(fill = "grey"),
    strip.text = element_text(face = "bold"),
    legend.title = element_blank(),
    legend.position = "bottom"
  )
}
  
graph_color <- "#006666"
```

The dataset is already on my Desktop, thus I'll just import it to R Studio using "readxl" package.

```{r,eval=T,echo=T,warning=F,message=F}
df <- readxl::read_xls("C:/Users/francisco.piccolo/Desktop/R/02.Data_bases/Global Superstore.xls")
```

Lets see the data structure using a sample of 10 rows of the dataset. For this, I'll use the **dim** function that inform the dimension of my dataset in terms of rows and columns. The **sample** function will be used to generate the 10 samples from the dataset.

```{r,eval=T,echo=T,warning=F,message=F}
dim(df)

df[sample(nrow(df),10), ]
```

Also, lets see if there are null values on this dataset through the **Amelia** package, that has the **missmap** function that shows in a graph the null values of the hole dataset.

```{r,eval=T,echo=T,warning=F,message=F}
Amelia::missmap(df)
```

We can see that some fields are incorrectly named (i.e. with spaced separating compound names), thus I'll adjust these fields to simplify future data manipulation.

```{r,eval=T,echo=T,warning=F,message=F}
df_adj <- df %>% 
  transmute(
    order_date = `Order Date`,
    customer = `Customer ID`,
    segment = Segment,
    category = Category,
    sub_category = `Sub-Category`,
    city = City,
    ship_date = `Ship Date`,
    ship_mode = `Ship Mode`,
    product_id = `Product ID`,
    order_priority = `Order Priority`,
    product_name = `Product Name`,
    market = Market,
    region = Region,
    qty = Quantity,
    sales = Sales,
    profit = Profit,
    shipping_cost = `Shipping Cost`,
    discount = Discount
  )
```

Now with the fields adjusted, we can start the EDA task, remembering that the goal will be generate recommendation for the supposed directors of this company. Before we start, it's interesting to establish a reasoning line to approach the dataset. Another important point to have in mid is that if the analyst overly "torture" the data, it will confess anything even if it isn't the truth. John Tukey mention this on his conferencies about exploratory data analysis and in his books, trying to explain that too many data manipulations can lead to incorrect conclusions if they're incorrectly made.

The reasoning that I'll follow to approach this task will be (i) visualize the financial data through time series plots in order to verify trendings and sazonality on financial indicators of the company; (ii) analyse market sales to identify areas to improve; (iii) analyse the product portfolio to see if there are products undermining the profit margin; (iv) analyse the operational aspect of the business to identify strategies that must change in order to recover profit margin.

In this dataset, there're commercial informations, where the company sells for the whole world office products and technologic products. The dataset presents revenue, profit, discount and delivery cost, that I'll call financial data. As well as this information, the dataset contain customer, product and operational data.

## **Time series of financial data**

To begin, lets dive in on the financial indicators of the company. The following graph presents revenue throughout 2011-2015 period. As the revenue variation is too high I opted to smooth the line with a moving average of 30 days to ease de visualization.

```{r,eval=T,echo=T,warning=F,message=F}
df_adj %>% 
  mutate(year = as.numeric(substr(order_date,1,4))) %>% 
  group_by(order_date) %>% 
  summarise(sales = sum(sales)) %>% 
  mutate(roll_avg_sales = zoo::rollmean(sales, 30, na.pad = T, align = "right")) %>% 
  ggplot()+
  geom_line(aes(x = order_date, y = roll_avg_sales, color = "roll_avg_sales"))+
  geom_line(aes(x = order_date, y = sales, color = "sales"), alpha = .1)+
  geom_smooth(aes(x = order_date, y = roll_avg_sales, color = "trend"), method = "lm")+
  scale_y_continuous(labels = scales::comma)+ 
  scale_color_manual(values = c("sales" = "black",
                                "roll_avg_sales" = graph_color,
                                "trend" = "red"),
                     labs(color = ""))+
  theme_graph()+
  labs(title = "Daily revenue time series",
       subtitle = "Growth treding and sazonality",
       x = "Sales Date",
       y = "Revenue",
       caption = "30 days moving average")
```

At the above graph, the sales present sazonality and also it shows that the company is expanding. Lets see on the next graph if the profit's followed the same pattern.

```{r,eval=T,echo=T,warning=F,message=F}
df_adj %>% 
  mutate(year = as.numeric(substr(order_date,1,4))) %>% 
  group_by(order_date) %>% 
  summarise(sales = sum(sales),
            profit = sum(profit)) %>% 
  mutate(roll_avg_profit = zoo::rollmean(profit, 30, na.pad = T, align = "right")) %>% 
  ggplot()+
  geom_line(aes(x = order_date, y = roll_avg_profit, color = "roll_avg_profit"))+
  geom_line(aes(x = order_date, y = profit, color = "profit"), alpha = .1)+
  geom_smooth(aes(x = order_date, y = roll_avg_profit, color = "trend"), method = "lm")+
  scale_y_continuous(labels = scales::comma)+
  scale_color_manual(values = c("profit" = "black",
                                "roll_avg_profit" = graph_color,
                                "trend" = "red"),
                     labs(color = ""))+
  theme_graph()+
  labs(title = "Daily profit time series",
       x = "",
       y = "",
       caption = "30 days moving average")
```

The profit is following the same pattern of the sales, however the visualization has gotten a little bit distorced on behalf of net lost earned at some days. It's seems prefered to normalize the profit by the revenue sold to get profit margin. Lets see this metric at the following graph.

```{r,eval=T,echo=T,warning=F,message=F}
df_adj %>%
  group_by(order_date) %>% 
  summarise(sales = sum(sales),
            profit = sum(profit)) %>% 
  mutate(roll_sum_sales = zoo::rollsum(sales, 30, na.pad = T, align = "right"),
         roll_sum_profit = zoo::rollsum(profit, 30, na.pad = T, align = "right")) %>% 
  mutate(profit_p = round(roll_sum_profit/roll_sum_sales,digits = 4),
         profit_mg = round(profit/sales, digits = 4)) %>% 
  ggplot()+
  geom_line(aes(x = order_date, y = profit_p, color = "roll_avg_profit"))+
  #geom_line(aes(x = order_date, y = profit_mg, color = "profit"), alpha = .2)+
  scale_y_continuous(labels = scales::percent)+
  scale_color_manual(values = c("roll_avg_profit" = graph_color,
                                "profit" = "black"),
                     labs(color = ""))+
  theme_graph()+
  labs(title = "Profit margin time series",
       x = "",
       y = "",
       caption = "30 days moving average")
```

Beyong profit, it's important to see if delivery costs stayed stable during the period. In accordance with the following graph, apparently the company didn't gain operational improvement event with the revenue growth.

```{r,eval=T,echo=T,warning=F,message=F}
df_adj %>%
  group_by(order_date) %>% 
  summarise(sales = sum(sales),
            shipping_cost = sum(shipping_cost)) %>% 
  mutate(roll_sum_sales = zoo::rollsum(sales, 30, na.pad = T, align = "right"),
         roll_sum_shipping_cost = zoo::rollsum(shipping_cost, 30, na.pad = T, align = "right")) %>% 
  mutate(shipping_cost = round(roll_sum_shipping_cost/roll_sum_sales,digits = 4)) %>% 
  ggplot()+
  geom_line(aes(x = order_date, y = shipping_cost, group = 1), color = graph_color)+
  scale_y_continuous(labels = scales::percent)+
  theme_graph()+
  labs(title = "Delivery cost time series",
       x = "",
       y = "",
       caption = "30 days moving average")
```

Finally, lets see how the discount strategy was implemented during the period. The following graph will show the average discount in proportion of the revenue.

```{r,eval=T,echo=T,warning=F,message=F}
df_adj %>%
  mutate(discount_amount = discount * sales) %>% 
  group_by(order_date) %>% 
  summarise(sales = sum(sales),
            shipping_cost = sum(shipping_cost),
            discount = sum(discount_amount)) %>% 
  mutate(roll_sum_sales = zoo::rollsum(sales, 30, na.pad = T, align = "right"),
         roll_sum_shipping_cost = zoo::rollsum(shipping_cost, 30, na.pad = T, align = "right"),
         roll_sum_discount = zoo::rollsum(discount, 30, na.pad = T, align = "right")) %>%
  mutate(discount = round(roll_sum_discount/roll_sum_sales,digits = 4)) %>% 
  ggplot()+
  geom_line(aes(x = order_date, y = discount, group = 1), color = graph_color)+
  scale_y_continuous(labels = scales::percent)+
  theme_graph()+
  labs(title = "Discount margin time series",
       x = "",
       y = "",
       caption = "30 days moving average")
```

After we get the time series of financial metrics, we can walk in on onther aspects of the business to generate some business recommendations.

## **Region**

On the following graphs, we'll see the region that generates more profit for the company. Also, we'll analyse if the delivery cost in relation to the revenue varies between regions.

```{r,eval=T,echo=T,warning=F,message=F}
graph_1 <- df_adj %>% 
  filter(order_date >= "2014-01-01") %>% 
  group_by(region) %>% 
  summarise(sales = sum(sales),
            profit = sum(profit),
            shp_cost = sum(shipping_cost)) %>% 
  ungroup() %>% 
  mutate(region = fct_reorder(region, sales)) %>% 
  ggplot()+
  geom_col(aes(x = region, y = sales), fill = graph_color)+
  scale_y_continuous(labels = scales::comma)+ 
  theme_graph()+
  coord_flip()+
  labs(y = "Sales",
       x = "")

graph_2 <- df_adj %>% 
  filter(order_date >= "2014-01-01") %>% 
  group_by(region) %>% 
  summarise(sales = sum(sales),
            profit = sum(profit),
            shp_cost = sum(shipping_cost)) %>% 
  mutate(profit_mg = round(profit/sales, digits = 4)) %>% 
  ungroup() %>% 
  mutate(region = fct_reorder(region, sales)) %>% 
  ggplot()+
  geom_col(aes(x = region, y = profit_mg), fill = graph_color)+
  scale_y_continuous(labels = scales::percent)+
  theme_graph()+
  coord_flip()+
  labs(y = "Profit margin",
       x = "",
       caption = "")

graph_3 <- df_adj %>% 
  filter(order_date >= "2014-01-01") %>% 
  group_by(region) %>% 
  summarise(sales = sum(sales),
            profit = sum(profit),
            shp_cost = sum(shipping_cost)) %>% 
  mutate(profit_mg = round(profit/sales, digits = 4),
         ship_cost_mg = round(shp_cost/sales, digits = 4)) %>% 
  ungroup() %>% 
  mutate(region = fct_reorder(region, sales)) %>% 
  ggplot()+
  geom_col(aes(x = region, y = ship_cost_mg), fill = graph_color)+
  scale_y_continuous(labels = scales::percent)+
  theme_graph()+
  coord_flip()+
  labs(y = "Delivery cost",
       x = "",
       caption = "Period: 2014 e 2015")

graph_4 <- df_adj %>% 
  mutate(discount_amount = discount * sales) %>% 
  filter(order_date >= "2014-01-01") %>% 
  group_by(region) %>% 
  summarise(sales = sum(sales),
            profit = sum(profit),
            shp_cost = sum(shipping_cost),
            discount = sum(discount_amount)) %>% 
  mutate(profit_mg = round(profit/sales, digits = 4),
         ship_cost_mg = round(shp_cost/sales, digits = 4),
         discount_mg = round(discount/sales, digits = 4)) %>% 
  ungroup() %>% 
  mutate(region = fct_reorder(region, sales)) %>% 
  ggplot()+
  geom_col(aes(x = region, y = discount_mg), fill = graph_color)+
  scale_y_continuous(labels = scales::percent)+
  theme_graph()+
  coord_flip()+
  labs(y = "Discount margin",
       x = "",
       caption = "Period: 2014 e 2015")

gridExtra::grid.arrange(graph_1,graph_2, graph_3,graph_4, ncol = 2, nrow = 2, top = textGrob("Revenue, Profit, Delivery cost and discount per region"))
```

Apparently, Canada is the region to receive more attention, since it has a profit margin higher than the average, maybe it's because the discount policy is different atthere. On the other hand, South East Asia needs some strategy change in order to reach the other countries in profit margins. The delivery cost is the same between reagions.

## **Product Category and Sub-category**

The company works with three product categories: Technologic, Furniture and Office supplies. In the next visualization, we'll see which category has gained traction along the period as well as the profit margin of each of them

```{r,eval=T,echo=T,warning=F,message=F}
df_adj %>%
  group_by(category, order_date) %>% 
  summarise(sales = sum(sales)) %>% 
  ggplot()+
  geom_smooth(aes(x = order_date, y = sales, group = category, color = category), se = F)+
  scale_y_continuous(labels = scales::comma)+ 
  theme_graph()+
  labs(title = "Category sales time series",
       x = "",
       y = "")
```

Apparently three categories present similar behavior during the period, having the technologic category as the most sold. Following we'll see which one have bring the highest profit margin.

```{r,eval=T,echo=T,warning=F,message=F}
df_adj %>%
  filter(order_date >= "2014-01-01") %>% 
  group_by(category) %>% 
  summarise(sales = sum(sales),
            profit = sum(profit),
            shp_cost = sum(shipping_cost)) %>% 
  mutate(profit_mg = round(profit/sales, digits = 4)) %>% 
  ggplot()+
  geom_col(aes(x = category, y = profit_mg), fill = graph_color)+
  scale_y_continuous(labels = scales::percent)+ 
  theme_graph()+
  labs(title = "Category profit margin",
       x = "",
       y = "",
       caption = "Period: 2014 e 2015")
```

The technologic products presents the highest profit margin, thus the company is on the right track in its comercial strategy. Now lets analyse the product categories with focus on discount and delivery cost.

```{r,eval=T,echo=T,warning=F,message=F}
df_adj %>% 
  mutate(discount = discount * sales) %>% 
  filter(order_date >= "2014-01-01") %>% 
  group_by(category) %>% 
  summarise(sales = sum(sales),
            discount = sum(discount),
            shipping_cost = sum(shipping_cost)) %>% 
  mutate(discount_mg = round(discount/sales, digits = 4),
         shipping_cost_mg = round(shipping_cost/sales, digits = 4)) %>% 
  select(category, discount_mg, shipping_cost_mg) %>% 
  tidyr::gather("campo","valor",2:3) %>% 
  ggplot(aes(x = category, y = valor, fill = campo))+
  geom_col(position = "dodge",alpha = .6)+
  scale_fill_manual(values = c("discount_mg" = graph_color,
                               "shipping_cost_mg" = "blue"),
                    labs(color = ""))+
  scale_y_continuous(labels = scales::percent)+
  theme_graph()+
  labs(title = "Discount and delivery cost by category",
       x = "",
       y = "")
```

The graph above indicates that the discount applied for the "Technology" category is lower and the delivery cost is stable for all three categories. Finishing the focus on product category, we can see that there isn't an urgent recommendation to be made for the company's directors. Lets dive in on the sub-category part of the analyse.

```{r,eval=T,echo=T,warning=F,message=F}
df_adj %>%
  filter(order_date >= "2014-01-01") %>% 
  group_by(sub_category) %>% 
  summarise(sales = sum(sales),
            profit = sum(profit),
            shp_cost = sum(shipping_cost)) %>% 
  mutate(profit_mg = round(profit/sales, digits = 4)) %>% 
  ungroup() %>% 
  mutate(sub_category = fct_reorder(sub_category, profit_mg)) %>% 
  ggplot()+
  geom_col(aes(x = sub_category, y = profit_mg), fill = graph_color)+
  scale_y_continuous(labels = scales::percent)+ 
  theme_graph()+
  labs(title = "Profit margin by product category",
       x = "",
       y = "",
       caption = "Period: 2014 e 2015")+
  coord_flip()
```

Its possible to note that "Tablets" is very prejudicial for the company. Maybe the discount applied for this sub-category is undermining the market rentability. The following graph presents the discount applied for each sub-category.

```{r,eval=T,echo=T,warning=F,message=F}
df_adj %>%
  mutate(discount = discount * sales) %>% 
  filter(order_date >= "2014-01-01") %>% 
  group_by(sub_category) %>% 
  summarise(sales = sum(sales),
            profit = sum(profit),
            shp_cost = sum(shipping_cost),
            discount = sum(discount)) %>% 
  mutate(discount_mg = round(discount/sales, digits = 4)) %>% 
  ungroup() %>% 
  mutate(sub_category = fct_reorder(sub_category, discount_mg)) %>% 
  ggplot()+
  geom_col(aes(x = sub_category, y = discount_mg), fill = graph_color)+
  scale_y_continuous(labels = scales::percent)+ 
  theme_graph()+
  labs(title = "Average discount margin by product category",
       x = "",
       y = "",
       caption = "Period: 2014 e 2015")+
  coord_flip()
```

Clearly the discount policy for "Tablets" will need a revision. This sub-category has 366 different products, lets see which one are receiving the highest discount, the profit margin and the revenue sold. The following graph show this view.

```{r,eval=T,echo=T,warning=F,message=F}
df_adj %>% 
  mutate(discount = discount * sales) %>% 
  filter(sub_category == "Tables") %>% 
  select(sub_category, sales, product_id, discount, profit) %>% 
  group_by(product_id) %>% 
  summarise(sales = sum(sales),
            profit = sum(profit),
            discount = sum(discount)) %>% 
  mutate(profit_mg = round(profit/sales, digits = 4),
         discount_mg = round(discount/sales, digits = 4),
         Product_demand = ifelse(sales >= 3000, "high_demand","low_demand")) %>% 
  filter(profit_mg >= -2) %>% 
  ggplot()+
  geom_point(aes(x = profit_mg, y = discount_mg, size = sales, color = Product_demand), shape = 20, alpha = .6)+
  geom_vline(xintercept = 0, lty = 2, color = "red")+
  scale_x_continuous(labels = scales::percent)+
  scale_y_continuous(labels = scales::percent)+
  scale_color_manual(values = c("high_demand" = "black",
                                "low_demand" = "dark orange"))+
  theme_graph()+
  labs(title = "Product profit and discount margin relation",
       x = "Profit margin",
       y = "Discount")
```

A lot of products selling a relevant quantity (above 3.000 unities on the considered period) and with a high discount portion making the sales prejudicial for the company. It's necessary to verify if this also occurs with other sub-categories.

```{r,eval=T,echo=T,warning=F,message=F}
df_adj %>% 
  mutate(discount = discount * sales) %>% 
  select(sub_category, sales, product_id, discount, profit) %>% 
  group_by(product_id, sub_category) %>% 
  summarise(sales = sum(sales),
            profit = sum(profit),
            discount = sum(discount)) %>% 
  mutate(profit_mg = round(profit/sales, digits = 4),
         discount_mg = round(discount/sales, digits = 4),
         Product_demand = ifelse(sales >= 3000, "high_demand","low_demand")) %>% 
  ungroup() %>% 
  mutate(sub_category = fct_relevel(sub_category, levels = c("Tables","Machines","Chairs","Supplies","Storage","Furnishings","Bookcases","Phones","Fasteners","Binders","Appliances","Envelopes","Art","Accessories","Copiers","Labels","Paper"))) %>% 
  filter(profit_mg >= -2) %>% 
  ggplot()+
  geom_point(aes(x = profit_mg, y = discount_mg, size = sales, color = Product_demand), shape = 20, alpha = .5)+
  geom_vline(xintercept = 0, lty = 2, color = "red")+
  scale_x_continuous(labels = scales::percent)+
  scale_y_continuous(labels = scales::percent)+
  scale_color_manual(values = c("high_demand" = "black",
                                "low_demand" = "dark orange"))+
  theme_graph()+
  facet_wrap(~sub_category)
```

Seems that products from other sub-categories don't have the same aggressive discount policy. Thus, the sub-category "Tablets" and "Machines" present a lot of black points at the left part of the graph (separeted by the red line). We can conclude that the company's directors will need some adjustments on this discount policy.

## **Operations**

In this topic we'll analyse the financial metrics by the operational perspective, aiming to analyse if the order criticality and the delivery contract cause some financial impact.

```{r,eval=T,echo=T,warning=F,message=F}
df_adj %>% 
  filter(order_date >= "2014-01-01") %>% 
  group_by(order_priority, ship_mode) %>% 
  summarise(sales = sum(sales),
            profit = sum(profit),
            shipping_cost = sum(shipping_cost)) %>% 
  ungroup() %>% 
  mutate(order_priority = fct_relevel(order_priority, levels = c("Low","Medium","High","Critical"))) %>% 
  ggplot(aes(x = order_priority, y = sales, fill = ship_mode))+
  geom_col(alpha = .7)+
  scale_y_continuous(labels = scales::comma)+
  scale_fill_brewer(type = "qual")+
  theme_graph()+
  labs(title = "Sales by order priority and delivery contract",
       x = "",
       y = "")
```

```{r,eval=T,echo=T,warning=F,message=F}
df_adj %>%
  filter(order_date >= "2014-01-01",
         sub_category != "Tables") %>% 
  mutate(profit_mg = round(profit/sales, digits = 4)) %>%
  mutate(order_priority = fct_relevel(order_priority, levels = c("Low","Medium","High","Critical")),
         ship_mode = fct_relevel(ship_mode, levels = c("Standard Class","Second Class","First Class","Same Day"))) %>% 
  ggplot(aes(x = profit_mg))+
  geom_histogram(alpha = .6, binwidth = .1, fill = graph_color)+
  geom_vline(xintercept = 0, lty = 2, color = "red")+
  scale_x_continuous(labels = scales::percent)+
  theme_graph()+
  labs(title = "Operational scenarios and profit margin",
       x = "",
       y = "")+
  facet_grid(order_priority~ship_mode, scales = "free")
```

Apparently the operational scenario isn't a culprit of profit margin. Orders with low priority are shipped within the "Standard Class" delivery contract (and it's correct). On the other hand, orders with the highest priority aren't sent by the "Standard Class" delivery contract. Finally, we conclude for this topic that the operational perspective can't explain much of the profit margin variation, neither generate some recommendation for the company's directors.

## **Conclusions and recommendations**

Considering the business aspects being analysed I come with some recommendations. First, the company has to verify its discount policy, urgently for its "Tablets" sub-category, since a lot of sales turns out to be prejudicial given the discount allowed. Second, it's important to pay more attention for the Canadian operations, because it's a prosperous market for the company. Third, the South East Asian market will need some attention in order to catch up with other regions on profit margin.
