---
title: "Estudo de regressão logística com a base de dados Titanic (kaggle)"
output: 
  prettydoc::html_pretty:
    theme: cayman
    fig_width: 6
    fig_height: 4
    fig_caption: true
---

#### Introdução

Regressão logistica é muito usada para prever a ocorrência de um evento baseando-se em variáveis categóricas preditoras. Usada muito para prever outputs qualitativos, como por exemplo, o e-mail é spam ou não, o passageiro gostou ou não do atendimento, etc. É uma alternativa À regressão linear que gera resultados quantitativos para o Y. Regressão logistica, apesar de ter regressão no nome, é um algoritmo de classificação. O output será uma probabilidade que se aproximará de 1 ou 0. Este algoritmo se fundamenta em uma função sigmoide e trabalha com o conceito de probabilidade e chance.

$$p = \frac{odd}{1+odd} >> odd = \frac{p}{1-p}$$

Pontos para se lembrar:

logit = log(odd)

#### Baixando os pacotes necessários

```{r}
library(tidyr)
library(tidyverse)
library(gridExtra)
library(Amelia)
library(readr)
library(ROCit)
library(rlang)

th <- theme_light()
```

#### Importando os dados do titanic

Use na.strings = c("") para que os valores vazios sejam substituidos por N.A.

```{r}
training_data <- read.csv("C:/Users/francisco.piccolo/Desktop/training_databases/titanic_kaggle_db/train.csv",header = T,na.strings = c(""))
```

Nem todos os campos serão usados no modelo, por isso é interessante selecionar apenas os campos que vão ser usados para depois realizar o tratamento dos dados.
```{r}
adj_training_data <- subset(training_data,select=c(2,3,5,6,7,8,10,12))
```

Após importar os dados, como o objetivo é executar uma regressão logística que irá classificar os passageiros em (sobrevivente = 1 e não sobrevivente = 0), é importante ver como a base de treino divide estes passageiros.

```{r}
table(adj_training_data$Survived)
```

Na base de treino, 38% dos passageiros sobreviveram. Ou seja, a base está bem balanceada (uma questão recorrente para quem aplica este tipo de algoritmo).

Após entender isso, resta saber se a base já está tratada. O primeiro tratamento se refere aos valores nulos de cada campo. O gráfico abaixo mostra estes casos.

```{r}
Amelia::missmap(adj_training_data,main = "Missing values vs Observed")
```

Nota-se que o campo Age e Embarked possuem dados vazios. Estes deverão ser tratados. O código abaixo irá colocar para o campo Age a idade média dos passageiros, uma boa alternativa para tratar valores nulos. Já para o campo Embarked, o campo nulo será removido.

```{r}
adj_training_data$Age[is.na(adj_training_data$Age)] <- mean(adj_training_data$Age,na.rm=T)

adj_training_data <- adj_training_data[!is.na(adj_training_data$Embarked),]
```

Veja o mesmo gráfico anterior com a base ajustada, ou seja, sem valores nulos.
```{r}
Amelia::missmap(adj_training_data,main = "Missing values vs Observed")
```

Após ter a base tratada, resta realizar uma análise exploratória para tentar identificar quais são as variáveis relevantes para o modelo.

O gráfico abaixo indica que a idade é um bom parâmetro para classificar um sobrevivente de um não sobrevivente. Veja que se o passageiro for novo (menos de 10 anos), a chance de sobreviver é alta.
```{r}
adj_training_data %>% 
  select(
    Age,
    Survived
  ) %>% 
  mutate(
    Age_2 = round(Age,digits = 0)
  ) %>% 
  group_by(Age_2,Survived) %>% 
  summarise(count = n()) %>% 
  filter(count < 125) %>% 
  ggplot(aes(x=Age_2,y=count,fill=Survived))+
  geom_bar(stat = "identity")
```

Vamos aplicar este mesmo gráfico para outras variáveis categóricas. Agora para a classe. A classe 1 pagou mais caro e a classe 3 mais barato pela passagem. Veja que se o passageiro for da classe 1, terá maiores chances de sobreviver do acidente.
```{r}
adj_training_data %>% 
  select(
    Pclass,
    Survived
  ) %>% 
  group_by(Pclass,Survived) %>% 
  summarise(count = n()) %>% 
  ggplot(aes(x=Pclass,y=count,fill=Survived))+
  geom_bar(stat = "identity")
```

Agora vamos ver como fica esta distribuição para os gêneros. Se o passageiro for mulher, há maiores chances de sobreviver.
```{r}
adj_training_data %>% 
  select(
    Sex,
    Survived
  ) %>% 
  group_by(Sex,Survived) %>% 
  summarise(count = n()) %>% 
  ggplot(aes(x=Sex,y=count,fill=Survived))+
  geom_bar(stat = "identity")
```

Com 3 parâmetros já é possível desenvolver um modelo interessante. Vamos selecionar apenas estas 3 variáveis para criar o modelo.

```{r}
df_titanic <- adj_training_data %>% 
  mutate(
    Age = round(Age,digits = 0)
  ) %>% 
  select(
    Pclass,
    Age,
    Sex,
    Survived
  )
```

```{r}
rl_titanic <- glm(formula = Survived~.,family = binomial(link = "logit"),data = df_titanic)

summary(rl_titanic)
```

Veja que o modelo trouxe, para cada um dos parâmetros, valores negativos.

Lembrando da fórmula da funçaõ sigmoide:

$$P(y=1) = \frac{1}{1+e^{-(\beta_{0} + \beta_{1} X_{1} + \beta_{2} X_{2} + \beta_{3} X_{3})}}$$
Onde:

$$ \beta_{0} = Intercepto = 4.72 $$ 
$$ \beta_{1} = Classe = -1.16 $$ 
$$ \beta_{2} = Age = -0.033 $$ 

$$ \beta_{3} = Sex = -2.60 $$ 

Com esta fórmula e com os valores destes parâmetros, é possível perceber que:

A classe tendo um parâmetro negativo, mostra que a pessoa sendo da 3ª classe, tem menor chance de sobreviver. Pois o parâmetro negativo irá sair do parenteses e ficar positivo, desta forma o e neperiano ficará no denominador da fórmula. O parâmetro será multiplicado pela classe, que pode ser 1, 2 ou 3. Se for um, o denominador será (tudo o mais constante):

$$P (y=1) = \frac{1}{1+e^{-(-1.16(classe))}}$$
$$P (y=1) = \frac{1}{1+e^{1.16(classe)}}$$
$$P (y=1) = \frac{1}{1+e^{1.16(1)}}$$
$$P (y=1) = \frac{1}{1+e^{1.16(2)}}$$

$$P (y=1) = \frac{1}{1+e^{1.16(3)}}$$

Ou seja, conforme a classe aumenta (3ª classe sendo a mais pobre), o modelo mostra que realmente se reduz a chance de sobrevivência, pois o denominador da equação aumenta. Isso se aplica aos outros parâmetros também. 

Resta agora aplicar este modelo para gerar a probabilidade para cada parâmetro da base do titanic.
```{r}
predict_titanic <- predict(rl_titanic,type = "response")

df_titanic_model <- cbind(df_titanic, predict_titanic)
  
df_titanic_model$survived_model <- ifelse(df_titanic_model$predict_titanic > .8,1,0)
```

Após aplicar o modelo na base e setar um limite de 0.5, onde acima deste limite (no caso a probabilidade estar acima ou abaixo dele), o passageiro receberá 1 e abaixo dele o passageiro receberá 0 (não sobreviveu). A tabela abaixo apresenta uma matriz (a.k.a matriz de confusão), apresentando os valores 0 e 1 original e os valores 0 e 1 previstos pelo modelo. Com esta matriz é possível gerar vários indicadores de acuracidade do modelo, um deles é a razão entre true poitives + true negatives sobre o total de registros analisados.
```{r}
table <- table(df_titanic$Survived,df_titanic_model$survived_model)

table

tn <- table[1,1]
fn <- table[2,1]
fp <- table[1,2]
tp <- table[2,2]

accuracy <- (tp+tn)/(tn+tp+fn+fp)
```

Outras duas medidas boas para acuracidade são precision and recall. A primeira mede a precisão dos valores positivos, ou seja, (tp/(tp+fp)) e a segunda mede a precisão dos valores negativos. Para um modelo que definiu uma régua de .5 para classificar (1 e 0) as duas métricas trarão o mesmo resultado.

```{r}
precision <- tp/(tp+fp)

recall <- tn/(tn+fn)
```



```{r}
roc_empirival <- ROCit::rocit(score = df_titanic_model$Survived,class = df_titanic_model$survived_model)
```


